\documentclass{article}
\usepackage{hevea}

\def\secref#1{Section~\ref{sec-#1}}
\def\chref#1{Chapter~\ref{ch-#1}}

%----------------------------------------------------------------------
% MACROS

\newcommand{\hsp}{\hspace{0.5in}}
\def\t#1{{\tt #1}}

%----------------------------------------------------------------------
\title{CIL}

% Make sure that all documents show up in the main frame
%HEVEA \AtBeginDocument{\@print{<base target="main">}}

\begin{document}
\maketitle

\section{Introduction}

 CIL ({\bf C} {\bf I}ntermediate {\bf L}anguage) is a high-level representation
along with a set of tools that permit easy analysis and source-to-source
transformation of C programs.

 CIL is both lower-level than abstract-syntax trees, by clarifying ambiguous
constructs and removing redundant ones, and also higher-level than typical
intermediate languages designed for compilation, by maintaining types and a
close relationship with the source program. The main advantage of CIL is that
it compiles all valid C programs into a few core constructs with a very clean
semantics. Also CIL has a syntax-directed type system that makes it easy to
analyze and manipulate C programs. Furtheremore, the CIL front-end is able to
process not only ANSI-C programs but also those using Microsoft C or GNU C
extensions. If you do not use CIL and want instead to use just a C parser and
analyze programs expressed as abstract-syntax trees then your analysis will
have to handle a lot of ugly corners of the language (let alone the fact that
parsing C itself is not a trivial task). See \secref{simplec} for some
examples of such extreme programs that CIL simplifies for you.

 In essence, CIL is a highly-structured, ``clean'' subset of C. CIL features a
reduced number of syntactic and conceptual forms. For example, all looping
constructs are reduced to a single form, all function bodies are given
explicit {\tt return} statements, syntactic sugar like {\tt "->"} is
eliminated and function arguments with array types become pointers. (For an
extensive list of how CIL simplifies C programs, see \sefrec{cabs2cil}.)
This reduces the number of cases that must be considered when manipulating a C
program. CIL also separates type declarations from code and flattens scopes
within function bodies. This structures the program in a manner more amenable
to rapid analysis and transformation. CIL computes the types of all program
expressions, and makes all type promotions and casts explicit. CIL supports
all GCC and MSVC extensions except for nested functions and complex numbers.
Finally, CIL organizes C's imperative features into expressions, instructions
and statements based on the presence and absence of side-effects and
control-flow. Every statement can be annotated with successor and predecessor
information. Thus CIL provides an integrated program representation that can
be used with routines that require an AST (e.g. type-based analyses and
pretty-printers), as well as with routines that require a CFG (e.g., dataflow
analyses).

 CIL comes accompanied by a number of Perl scripts that perform generally
useful operations on code:
\begin{itemize}
\item A \ahrefloc{sec-driver}{driver} which behaves as either the \t{gcc} or
Microsoft VC compiler and can invoke the preprocessor followed by the CIL
application. The advantage of this script is that you can easily use CIL and
the analyses written for CIL with existing make files.
\item A \ahrefloc {sec-merger}{whole-program merger} that you can use as a
replacement for your compiler and it learns all the files you compile when you
make a project and merges all of the preprocessed source files into a single
one. This makes it easy to do whole-program analysis.
\item A \ahrefloc{sec-patcher}{patcher} makes it easy to create modified
copies of the system include files. The CIL driver can then be told to use
these patched copies instead of the standard ones.
\end{itemize}

 CIL has been tested very extensively. It is able to process the SPECINT95
benchmarks, the Linux kernel, GIMP and other open-source projects. This adds
to about 1,000,000 lines of code that we tested it on. It is also able to
process the few Microsoft NT device drivers that we have had access to. CIL
was tested against GCC's c-torture testsuite and (except for the tests
involving complex numbers and inner functions, which CIL does not currently
implement) CIL passes most of the tests. Specifically CIL fails 23 tests out
of the 904 c-torture tests that it should pass. GCC itself fails 19 tests. A
total of 1400 regression test cases are run automatically on each change to
the CIL sources.

\section{Compiling C to CIL}\label{sec-cabs2cil}

 In this section we try to describe a few of the many transformations that are
applied to a C program to convert it to CIL. The module that implements this
conversion is about 5000 lines of OCaml code. In contrast a simple program
transformation that instruments all functions to keep a shadow stack of the
true return address (thus preventing stack smashing) is only 70 lines of code.
This example shows that the analysis is so much simpler because it has to
handle only a few simple C constructs and also because it can leverage on CIL
infrastructure such as visitors and pretty-printers.

 In no particular order these are a few of the most significant ways in which
C programs are compiled into CIL:
\begin{enumerate}
\item CIL will eliminate all declarations for unused entities. This means that
just because your hello world program includes \t{stdio.h} it does not mean
that your analysis has to handle all the ugly stuff from \t{stdio.h}.

\item Type specifiers are interpreted and normalized:
\begin{cilcode}[global]
int long signed x;
signed long extern x;
long static int long y;
\end{cilcode}

\item Anonymous structure and union declarations are given a name. 
\begin{cilcode}[global]
 struct { int x; } s;
\end{cilcode}

\item Nested structure tag definitions are pulled apart. This means that all
structure tag definitions can be found by a simple scan of the globals.

\begin{cilcode}[global]
struct foo {
   struct bar {
      union baz { 
          int x1; 
          double x2;
      } u1;
      int y;
   } s1;
   int z;
} f;
\end{cilcode}

\item All structure, union, enumeration definitions and the type definitions
from inners scopes are moved to global scope (with appropriate renaming). This
facilitates moving around of the references to these entities.

\begin{cilcode}[global]
int main() {
  struct foo { 
        int x; } foo; 
  {
     struct foo { 
        double d;
     };
     return foo.x;
  }      
}
\end{cilcode}

\item Prototypes are added for those functions that are called before being
defined. Furthermore, if a prototype exists but does not specify the type of
parameters that is fixed. But CIL will not be able to add prototypes for those
functions that are neither declared nor defined (but are used!).
\begin{cilcode}[global]
  int f();  // Prototype without arguments
  int f(double x) {
      return g(x);
  }
  int g(double x) {
     return x;
  } 
\end{cilcode}

\item Array lengths are computed based on the initializers or by constant
folding.
\begin{cilcode}[global]
  int a1[] = {1,2,3};
  int a2[sizeof(int) >= 4 ? 8 : 16];
\end{cilcode}

\item Enumeration tags are computed using constant folding:
\begin{cilcode}[global]
  enum { 
     FIVE = 5, 
     SIX, SEVEN, 
     FOUR = FIVE - 1, 
     EIGHT = sizeof(double)
  };
\end{cilcode}

\item Initializers are normalized to include specific initialization for the
missing elements:
\begin{cilcode}[global]
  int a1[5] = {1,2,3};
  struct foo { int x, y; } s1 = { 4 };
\end{cilcode}

\item Initializer designators are interpreted and eliminated. Subobjects are
properly marked with braces. CIL implements
the whole ISO C99 specification for initializer (neither GCC nor MSVC do) and
a few GCC extensions. 
\begin{cilcode}[global]
  struct foo { 
     int x, y; 
     int a[5];
     struct inner {
        int z;
     } inner;
  } s = { 0, .inner.z = 3, .a[1 ... 2] = 5, 4, y : 8 };
\end{cilcode}

\item String initializers for arrays of characters are processed

\begin{cilcode}[global]
char foo[] = "foo plus bar";
\end{cilcode}

\item String constants are concatenated

\begin{cilcode}[global]
char *foo = "foo " " plus " " bar ";
\end{cilcode}

\item Initializers for local variables are turned into assignments. This is in
order to separate completely the declarative part of a function body from the
statements. This has the unfortunate effect that we have to drop the \t{const}
qualifier from local variables !

\begin{cilcode}[local]
  int x = 5; 
  struct foo { int f1, f2; } a [] = {1, 2, 3, 4, 5 };
\end{cilcode}

\item Local variables in inner scopes are pulled to function scope (with
appropriate renaming). Local scopes thus disappear. This makes it easy to find
and operate on all local variables in a function.

\begin{cilcode}[global]
  int x = 5; 
  int main() {
    int x = 6;
    { 
      int x = 7;
      return x;
    }
    return x;
  } 
\end{cilcode}

\item Global declarations in local scopes are moved to global scope:
\begin{cilcode}[global]
  int x = 5; 
  int main() {
    int x = 6;
    { 
      static int x = 7;
      return x;
    }
    return x;
  } 
\end{cilcode}

\item Return statements are added for functions that are missing them. If the
return type is not a base type then a \t{return} without a value is added.
The guaranteed presence of return statements makes it easy to implement a
transformation that inserts some code to be executed immediately before
returning from a function.
\begin{cilcode}[global]
  int foo() {
    int x = 5;
  } 
\end{cilcode}

\item One of the most significant transformations is that expressions that
contain side-effects are separated into statements. 

\begin{cilcode}[local]
   int x, f(int);
   return (x ++ + f(x));
\end{cilcode}

 Internally, the \t{x ++} statement is turned into an assignment which the
pretty-printer prints like the original. CIL has only three forms of basic
statements: assignments, function calls and inline assembly.

\item Shortcut evaluation of boolean expressions and the \t{?:} operator are
compiled into explicit conditionals:
\begin{cilcode}[local]
  int x;
  int y = x ? 2 : 4;
  int z = x || y;
  // Here we duplicate the return statement
  if(x && y) { return 0; } else { return 1; }
  // To avoid excessive duplication, CIL uses goto's for 
  // statement that have more than 5 instructions
  if(x && y || z) { x ++; y ++; z ++; x ++; y ++; return z; }
\end{cilcode}

\item GCC's conditional expression with missing operands are also compiled
into conditionals:
\begin{cilcode}[local]
  int f();;
  return f() ? : 4;
\end{cilcode}

\item GCC's 

\item All forms of loops (\t{while}, \t{for} and \t{do}) are compiled
internally as a single \t{while(1)} looping construct with explicit \t{break}
statement for termination. For simple \t{while} loops the pretty printer is
able to print back the original:
\begin{cilcode}[local]
   int x, y;
   for(int i = 0; i<5; i++) {
      if(i == 5) continue;
      if(i == 4) break;
      i += 2;
   } 
   while(x < 5) {
     if(x == 3) continue;
     x ++;
   }
\end{cilcode}

\item GCC's block expressions are compiled away. (That's right there is an
infinite loop in this code.)

\begin{cilcode}[local]
   int x = 5, y = x;
   int z = ({ x++; L: y -= x; y;});
   return ({ goto L; 0; });
\end{cilcode}

\item CIL contains support for both MSVC and GCC inline assembly (both in one
internal construct)

\item CIL compiles away the GCC extension that allows many kinds of constructs
to be used as lvalues:

\begin{cilcode}[local]
   int x, y, z;
   return &(x ? y : z) - & (x ++, x);
\end{cilcode}

\item All types are computed and explicit casts are inserted for all
promotions and conversions that a compiler must insert:

\item CIL will turn old-style function definition (without prototype) into
new-style definitions. This will make the compiler less forgiving when
checking function calls, and will catch for example cases when a function is
called with too few arguments. This happens in old-style code for the purpose
of implementing variable argument functions. To make the code compile after
CIL we insert dummy arguments for the missing ones:
\begin{cilcode}[global]
#include <stdio.h>
int f(s1, s2) char *s1, *s2; {
  printf(s1, s2);
}

int main() {
    f("hello \%s!\n", "world");
    f("hello again\n"); // f called with only one argument
}
\end{cilcode}
 
\item Since CIL sees the source after preprocessing the code after CIL does
not contain the comments and the preprocessing directives.

\item CIL will remove from the source file those type declarations, local
variables and inline functions that are not used in the file. This means that
your analysis does not have to see all the ugly stuff that comes from the
header files: 
\begin{cilcode}[global]
#include <stdio.h>

typedef int unused_type;

inline char unused_inline (void) { return 0; }

int main() {
  int unused_local;
  printf("Hello world\n"); // Only printf will be kept from stdio.h     
}
\end{cilcode}

\end{enumerate}

\section{Using CIL}\label{sec-cil}
 
 In order to use CIL you must write an Ocaml module containing your analysis
and transformation, which you then link into our boilerplate application
called cilly. An example of such module is \t{logwrites.ml} (a module that is
distributed with CIL and whose purpose is to instrument code to print the
addresses of memory locations being written). (We plan to release a C-language
interface to CIL so that you can write your analyses in C instead of Ocaml.)
Assuming that you have written \t{logwrites.ml} here is how you use it: 

 \begin{enumerate}
 \item Put \t{logwrites.ml} in the \t{src} directory. This will make sure that
 \t{make} can find it. If you want to put it in some other directory modify
 the \t{Makefile} and add to \t{SOURCEDIRS} your directory. 

 \item Modify the \t{Makefile} and add your module to the \t{MODULES}
 variable. The order of the modules matters. Add your modules somewhere after
 \t{cil} and before \t{maincil}.

 \item Modify \t{maincil.ml} and add descriptions of the new command line
 options that you want to add to \t{cilly}. This is done by modifying the
 definition of \t{argDescr} variable using the convention of the Ocaml
 standard library module \t{Arg}. For \t{logWrites} we added the option
 \t{--logwrites} that sets a global variable that enables the \t{logWrites}
 transformatio.

 \item Modify \t{maincil.ml} add add a call to the top level function of your
 module to the body of the function \t{processOneFile}. Alternatively, you can
 call the \t{Frontc.parse: string -> unit -> Cil.file} function with the name
 of a file containing the output of the preprocessor and then invoke your
 analysis function on the resulting \t{Cil.file} data structure. Then you can
 call the function \t{Cil.printFile: out_channel -> Cil.file -> unit} to print
 the file to a given output channel.

 \item In the \t{cil} directory run \t{make} to make the bytecode version of
 the \t{cilly} application (in \t{obj/cilly.byte.exe}) and then run \t{make
 RELEASE=1} to also make the optimized version of the applciation (in
 \t{obj/cilly.asm.exe}). 

 \item Now you can invoke the \t{cilly} application on a preprocessed file, or
 instead use the \t{cilly.pl} driver which provides a convenient compiler-like
 interface to \t{cilly}. See \secref{driver} for details using \t{cilly.pl}.
 \end{enumerate}

 In the next section we give an overview of the API that you can use
to write your analysis and transformation. 
 
\section{CIL API Documentation}\label{sec-api} 

 The CIL API is documented in the file \t{src/cil.mli}. We also have an
\ahref{api/index.html}{online documentation}.  

  

\section{The CIL Driver}\label{sec-driver}

 We have packaged CIL as an application \t{cilly} that contains certain
example modules, such as \t{logwrites.ml} (a module
that instruments code to print the addresses of memory locations being
written). Normally, you write another module like that, add command-line
options and an invocation of your module in \t{src/main.ml}. Once you compile
CIL you will obtain the file \t{obj/cilly.asm.exe}. 

 We wrote a driver for this executable that makes it easy to invoke your
analysis on existing C code with very little manual intervention. This driver
is \t{lib/cilly.pl} and is quite powerful. 

 A simple use of the driver is:
\begin{verbatim}
perl lib/cilly.pl -D HAPPY_MOOD -I myincludes hello.c -o hello
\end{verbatim}

 This performs the following actions: 
\begin{itemize}
\item preprocessing using the -D and -I arguments with the resulting file left in \t{hello.i}, 
\item the invocation of the \t{cilly.asm} application which parses \t{hello.i}
coverts it to CIL and the pretty-prints it to \t{hellocil.c}
\item another round of preprocessing with the result placed in \t{hellocil.i}
\item the true compilation with the result in \t{hellocil.o}
\item a linking phase with the result in \t{hello}
\end{itemize}
 
 Note that \t{cilly.pl} behaves like the \t{gcc} compiler with the additional
effect that CIL sees all the source code. This makes it easy
to use it with existing \t{Makefiles}:
\begin{verbatim}
make CC="perl lib/cilly.pl" LD="perl lib/cilly.pl"
\end{verbatim}

 \t{cilly.pl} can also behave as the Microsoft Visual C compiler, if the first
 argument is \t{--mode=MSVC}:
\begin{verbatim}
perl lib/cilly.pl --mode=MSVC /D HAPPY_MOOD /I myincludes hello.c /Fe hello.exe
\end{verbatim}

 (This in turn will pass a \t{--MSVC} flag to the underlying \t{cilly.asm}
 process which will make it understand the Microsoft Visual C extensions)

 \t{cilly.pl} can also behave as the archiver \t{ar}, if it is passed an
argument \t{--mode=AR}. Note that only the \t{cr} mode is supported (create a
new archive and replace all files in there). Note that the previous version of
the archive is lost. 

 Furthermore, \t{cilly.pl} allows you to pass some arguments on to the
underlying \t{cilly.asm} process. As a general rule all arguments that start
with \t{--} and that \t{cilly.pl} itself does not process, are passed on. For
example, 
\begin{verbatim}
perl lib/cilly.pl --logwrites -D HAPPY_MOOD -I myincludes hello.c -o hello.exe
\end{verbatim}

 will produce a file \t{hellocil.c} that prints all the memory addresses
written by the application. 

 The most powerful feature of \t{cilly.pl} is that it can collect all the
sources in your project, merge them into one file and then apply CIL. This
makes it a breeze to do whole-program analysis and transformation. All you
have to do is to pass the \t{--merge} flag to \t{cilly.pl}:
\begin{verbatim}
make CC="perl lib/cilly.pl --logwrites --merge"
\end{verbatim}

 You can even leave some files untouched:
\begin{verbatim}
make CC="perl lib/cilly.pl --logwrites --merge --leavealone=foo --leavealone=bar"
\end{verbatim}

 This will merge all the files except those with the basename \t{foo} and
\t{bar}. Those files will be compiled as usual and then linked in at the very
end. 

 The sequence of actions performed by \t{cilly.pl} depends on whether merging
is turned on or not:
\begin{itemize}
\item If merging is off
  \begin{enumerate}
    \item For every file \t{file.c} to compile
         \begin{enumerate}
            \item Preprocess the file with the given arguments to 
                  produce \t{file.i}
            \item Invoke \t{cilly.asm} to produce a \t{filecil.c}
            \item Preprocess to \t{filecil.i}
            \item Invoke the underlying compiler to produce \t{filecil.o}
         \end{enumerate}
    \item Link the resulting objects
  \end{enumerate}
\item If merging is on
  \begin{enumerate}
    \item For every file \t{file.c} to compile
         \begin{enumerate}
            \item Preprocess the file with the given arguments to 
                  produce \t{file.i}
            \item Save the preprocessed source as \t{file.o}
         \end{enumerate}
    \item When linking executable \t{hello.exe}, look at every object 
          file that must be linked and see if it actually 
          contains preprocessed source. Pass all those files to a 
          special merging application (described in
          \secref{merger}) to produce \t{hello.exe\_comb.c}
    \item Invoke \t{cilly.asm} to produce a \t{hello.exe\_combcil.c}
    \item Preprocess to \t{hello.exe\_combcil.i}
    \item Invoke the underlying compiler to produce \t{hello.exe\_combcil.o}
    \item Invoke the actual linker to produce \t{hello.exe}
  \end{enumerate}
\end{itemize}

 Note that files that you specify with \t{--leavealone} are not merged and
never presented to CIL. They are compiled as usual and then are linked in at
the end. 

 And a final feature of \t{cilly.pl} is that it can substitute copies of the
system's include files:

\begin{verbatim}
make CC="perl lib/cilly.pl --includedir=myinclude"
\end{verbatim}

 This will force the preprocessor to use the file \t{myinclude/xxx/stdio.h}
(if it exists) whenever it encounters \t{#include <stdio.h>}. The \t{xxx} is
a string that identifies the compiler version you are using. This modified
include files should be produced with the patcher script (see
\secref{patcher}).

  \subsection{\t{cilly.pl} Options}

 Among the options for the \t{cilly.pl} you can put anything that can normally
go in the command line of the compiler that \t{cilly.pl} is impersonating.
\t{cilly.pl} will do its best to pass those options along to the appropriate
subprocess. In addition, the following options are supported:

\begin{itemize}
\item \t{--mode=mode} This must be the first argument if present. It makes
\t{cilly.pl} behave as a given compiled. The following modes are recognized: 
     \begin{itemize}
        \item GNUCC - the GNU C Compiler. This is the default.
        \item MSVC - the Microsoft Visual C compiler. Of course, you should
                     pass only MSVC valid options in this case. 
        \item AR - the archiver \t{ar}. Only the mode \t{cr} is supported and
                   the original version of the arhive is lost. 
     \end{itemize}
\item \t{--help} Prints a list of the options supported.
\item \t{--verbose} Prints lots of messages about what is going on.
\item \t{--stages} Less than \t{--verbose} but lets you see what \t{cilly.pl}
                   is doing. 
\item \t{--merge} This tells \t{cilly} to first attempt to collect into one
source file all of the sources that make your application, and then to apply
\t{cilly.asm} on the resulting source. The sequence of actions in this case is
described above and the merger itself is described in \secref{merger}.
\item \t{--leavealone=xxx}. Do not merge and do not present to CIL the files
whose basename is "xxx". These files are compiled as usual and linked in at
the end. 
\item \t{--includedir=xxx}. Override the include files with those in the given
directory. The given directory is the same name that was given an an argument
to the patcher (see \secref{patcher}). In particular this means that
that directory contains subdirectories named based on the current compiler
version. The patcher creates those directories. 
\item \t{--usecabs}. Do not CIL, but instead just parse the source and print
its AST out. This should looked like the preprocessed file.
\end{itemize}
 
 
  \subsection{\t{cilly.asm} Options}

 All of the options that start with \t{--} and are not understood by
\t{cilly.pl} are passed on to \t{cilly.asm}. The following options are
supported:
\begin{itemize}
\item \t{--out=xxx}. The name of the pretty-printed file.
\item \t{--verbose}. Print lots of random stuff. This is passed on from
\t{cilly.pl}.
\item \t{-help}. Print the help. Actually \t{cilly.pl} will do this if you
      pass it \t{--help}.  
\item \t{--check}. Run a consistency check over the CIL after every operation. 
\item \t{--MSVC}. Enable the MSVC extensions and pretty-print for consumption
by MSVC.
\item \t{--logcalls}. Insert code in the processed source to print the name of
funtions as are called. Implemented in \t{src/logcalls.ml}.
\item \t{--logwrites}. Insert code in the processed source to print the
address of all memory writes. Implemented in \t{src/logwrites.ml}.
\item \t{--heapify}. Apply the heapify transformation.
                     Implemented in \t{src/heapify.ml}.
\item \t{--heapify}. Apply the StackGuard transformation.
                     Implemented in \t{src/stackguard.ml}.
\item \t{--stages}. Print the stages that CCured is performing.
\item \t{--log=xxx}. Set \t{xxx} to be the name of the log file for the CCured
application. By default \t{stderr} is used.
\item \t{--keepunused}. Do not attempt to remove the unused variables and
       types from CIL. 
\item \t{--noPrintLn}. Do not print line numbers.
\item \t{--commPrintLn}. Print line numbers but in comments.
\end{itemize}


\section{Controlling CIL}

 In the process of converting a C file to CIL we drop the unused prototypes
and even inline function definitions. This results in much smaller files. If
you do not want this behavior then you must pass the \t{--keepunused} argument
to the CIL application. 

 Alternatively you can put the following pragma in the code (instructing CIL
to specifically keep the declarations and definitions of the function
\t{func1} and variable \t{var2}, the definition of type \t{foo} and of
structure \t{bar}):
\begin{verbatim}
#pragma cilnoremove("func1", "var2", "type foo", "struct bar")
\end{verbatim}


\section{Installation}

You will need OCaml release 3.02 or higher to build CIL. CIL has been tested
on Linux and on Windows (where it can behave at either Microsoft Visual C or
gcc). 

 If you want to use CIL on Windows then you must get a complete installation
of \t{cygwin} and the source-code OCaml distribution and compile it yourself
using the cygwin tools (as opposed to getting the Win32 native-code version of
OCaml). If you have not done this before then take a look
\ahref{../ccured/setup.html}{here}. (Don't need to worry about \t{cvs} and \t{ssh}
since you won't be using those.)

\begin{enumerate}
\item Unzip and untar the source distribution. This will create a directory
      called \t{cil} whose structure is explained below. \\
      \hsp\verb!tar xvfz cil.tar.gz!
\item Create an environment variable \t{ARCHOS} and set it to either
      \t{X86\_LINUX} or \t{x86\_WIN32}.
\item Enter the \t{cil} directory and run GNU make to build the 
      distribution.\\
      \hsp\verb!cd cil!\\
      \hsp\verb!make!\\
      \hsp\verb!make NATIVECAML=1!\\

\item You should now find \t{obj/cilly.asm.exe} and \t{obj/merger.asm.exe}
\end{enumerate}

The file \ahref{cil.tar.gz}{cil.tar.gz} contains the complete source CIL
distribution, consisting of the following files:

\begin{tabular}{ll}
Filename   & Description \\
\t{Makefile}                    & Makefile for building CIL \\
\t{Makefile.ocaml}              & A file that is included by \t{Makefile} \\
\t{doc/}                        & HTML documentation of the CIL API \\
\t{obj/}                        & Directory that will contain the compiled
                                   CIL modules and executables\\
\t{lib/cilly.pl}                & A Perl script that can be invoked with the 
                                  same arguments as either \t{gcc} or
                                  Microsoft Visual C and will convert the
                                  program to CIL, perform some simple
                                  transformations, emit it and compile it as
                                  usual. \\
\t{lib/CompilerStub.pm}         & A Perl class that can be used to write code
                                  that impersonates a compiler. \t{cilly.pl}
                                  uses it.  \\
\t{lib/Merger.pm}               &  A subclass of \t{CompilerStub.pm} that can
                                  be used to merge source files into a single
                                  source file.\t{cilly.pl}
                                  uses it. \\
\t{src/cil.ml,mli}              & Definition of CIL abstract syntax and
                                   utilities for manipulating it\\
\t{src/clist.ml,mli}            & Utilities for efficiently managing lists
                                   that need to be concatenated often\\
\t{src/errormsg.ml,mli}         & Utilities for error reporting \\
\t{src/frontc/}                 & The parser, the CIL converter and the 
                                  merger \\
\t{src/heapify.ml}              & A CIL transformation that moves array local
                                   variables from the stack to the heap \\
\t{src/logcalls.ml,mli}         & A CIL transformation that logs every
                                   function call \\
\t{src/logwrites.ml}            & A CIL transformation that logs every memory
                                   write \\
\t{src/main.ml}                 & A test application called \t{cilly} \\
\t{src/pretty.ml,mli}           & Utilities for pretty printing \\
\t{src/stats.ml,mli}            & Utilities for maintaining timing statistics
\\
\t{src/trace.ml,mli}            & Utilities useful for printing debugging
                                   information\\
\t{src/util.ml}                 & Miscellaneous functions and global variables
\end{tabular}


\section{GCC Extensions}

 The CIL parser handles most of the \t{gcc}
\ahref{http://gcc.gnu.org/onlinedocs/gcc-3.0.2/gcc_5.html#SEC67}{extensions}
and compiles them to CIL. The following extensions are not handled (note that
we are able to compile a large number of programs, including the Linux kernel,
without encountering these):

\begin{enumerate}
\item Nested function definitions.
\item Construcing function calls.
\item Naming an expression's type.
\item Complex numbers
\item Hex floats
\item Subscripts on non-lvalue arrays.
\item Forward function parameter declarations
\end{enumerate}

 The following extensions are handled, typically by compiling them away:
\begin{enumerate}
\item Attributes for functions, variables and types. In fact, we have a clear
specification (see \secref{attrib}) of how attributes are interpreted. The
specification extends that of \t{gcc}.
\item Old-style function definitions and prototypes. These are translated to
new-style. 
\item Locally-declared labels. As part of the translation to CIL, we generate
new labels as needed. 
\item Labels as values and computed goto. This allows a program to take the
address of a label and to manipulate it as any value and also to perform a
computed goto. We compile this by assigning each label whose address is taken
a small integer that acts as its address. Every computed \t{goto} in the body
of the function is replaced with a \t{switch} statement. If you want to invoke
the label from another function, you are on your own (the \t{gcc}
documentation says the same.)
\item Generalized lvalues. You can write code like \t{(a, b) += 5} and it gets
translated to CIL. 
\item Conditionals with omitted operands. Things like \t{x ? : y} are
translated to CIL.
\item Double word integers. The type \t{long long} and the \t{LL} suffix on
constants is understood. This is currently interpreted as 64-bit integers.
\item Local arrays of variable length. These are converted to uses of
\t{alloca}, the array variable is replaced with a pointer to the allocated
array and the instances of \t{sizeof(a)} are adjusted to return the size of
the array and not the size of the pointer. 
\item Non-constant local initializers. Like all local initializers these are
compiled into assignments. 
\item Compound literals. These are also turned into assignments.
\item Designated initializers. The CIL parser actually supports the full ISO
syntax for initializers, which is more than both \t{gcc} and \t{MSVC}. I
(George) think that this is the most complicated part of the C language and
whoever designed it should be banned from ever designing languages again.
\item Case ranges. These are commpiled into separate cases. There is no code
duplication, just a larger number of \t{case} statements.
\item Transparent unions. This is a strange feature that allows you to define
a function whose formal argument has a (tranparent) union type, but the
argument is called as if it were the first element of the union. This is
compiled away by saying that the type of the formal argument is that of the
first field, and the first thing in the function body we copy the formal into
a union. 

\item Inline assembly-language. The full syntax is supported and it is carried
as such in CIL.

\item Function names as strings. The identifiers \t{\_\_FUNCTION\_\_} and
\t{\_\_PRETTY\_FUNCTION\_\_} are replaced with string literals. 

\item Keywords \t{typeof}, \t{alignof}, \t{inline} are supported. 
\end{enumerate}

\section{CIL Limitations}

 There are several implementation details of CIL that might make it unusable
 or less than ideal for certain tasks:

\begin{itemize}
\item CIL operates after preprocessing. If you need to see comments, for
example, you cannot use CIL. But you can use attributes and pragmas instead.
And there is some support to help you patch the include files before they are
seen by the preprocessor. This is how we turn some #define that we don't like
into function calls for example. 

\item CIL does transform the code in a non-trivial way. This is done in order
to make most analyses easier. But if you want to see the code \t{e1, e2++}
exactly as it appears in the code, then you should not use CIL. 

\item CIL removes all local scopes and moves all variables to function
scope. It also separates a declaration with an initializer into a declaration
plus an assignment. The unfortunate effect of this transformation is that
local variables cannot have the \t{const} qualifier.

\end{itemize}
 
\section{Known Bugs}

\begin{itemize}

\item The implementation of \t{bitsSizeOf} does not take into account the
packing pragmas. Also, it appears that in some cases involving bitfields it is
not accurate on Linux. It was tested to be accurate on cygwin/gcc-2.95.3 and
on Windows/MSVC. 

\item We do not support tri-graph sequences (ISO 5.2.1.1).

\item GCC has a strange feature called ``extern inline''. Such a function can
be defined twice. First with the ``extern inline'' specifier and the second
time without it. If optimizations are turned off then the ``extern inline''
definition is considered a prototype (its body is ignored). If optimizations
are turned on then the extern inline function is inlined at all of its
occurences from the point of its definition all the way to the point where the
(optional) second definition appears. No body is generated for an extern
inline function. A body is generated for the real definition and that one is
used in the rest of the file. 

 CIL will rename your extern inline function (and its uses) with the suffix
 \t{\_\_extinline}. This means that if you have two such definition, that do
 different things and the optimizations are not on, then the CIL version might
 compute a different answer !

 Also, if you have multiple extern inline declarations then CIL will ignore
but the first one. This is not so bad because GCC itself would not like it. 

\item There are still a number of bugs in handling some obscure features of
GCC. For example, when you use variable-length arrays, CIL turnes them into
calls to \t{alloca}. This means that they are deallocated when the function
returns and not when the local scope ends. 
\end{itemize}

 And some limitations that are not really bugs:
\begin{itemize}
\item \t{long} and \t{int} are 32-bit, \t{short} is 16 bits. 

 

\end{itemize}


  \section{Using the merger}\label{sec-merger}

 There are many other program analyses that are more effective when
done on the whole program.

 The merger is a tool that combines all of the C source files in a project
into a single C file. There are two tasks that a merger must solve:
\begin{enumerate}
\item Detect what are all the sources that make a project and with what
compiler arguments they are compiled.

\item Merge all of the source files into a single file. 
\end{enumerate}

 For the first task the merger impersonates a compiler and a linker (both a
GCC and a Microsoft Visual C mode are supported) and it expect to be invoked
(from a build script or a Makefile) on all sources of the project. When
invoked to compile a source the merger just preprocesses the source and
saves using the name of the requested object file. By preprocessing this early
the merger is able to take into account variations in the command line
arguments that affect preprocessing of different source files. 

 When the merger is invoked in the place of the linker it collects the
preprocessed sources that were stored with the names of the object files, and
invoked the second part of the merger. Note that arguments that affect the
compilation or linking must be the same for all source files.

 For the second task, the merger essentially concatenates the preprocessed
sources with care to rename conflicting file-local declarations (we call this
process alpha-conversion or a file). The merger also attempts to remove
duplicate global declarations and definitions. Specifically the following
actions are taken: 

\begin{itemize}
\item File-scope names (\t{static} globals, names of types defined with
\t{typedef}, and structure/union/enumeration tags) are given new names if they
conflict with declarations from previously processed sources. The new name is
formed by appending the suffix \t{\_\_\_n}, where \t{n} is a unique integer
identifier. Then the new names are applied to their occurences in the file. 

\item Non-static declarations of globals are never renamed. But we try to
remove duplicate ones. The equality check is done on the whole structure of
the declaration (including the line-number information) after the body of the
declaration has been alpha-converted. This process is intended to remove those
declarations that originate from the same include file. Similarly, we try to
eliminate duplicate definitions of \t{inline} functions, since these
occasionally appear in include files.

\item Names of types and tags of structures or unions or enumerations are
considered to have file scope and thus are candidate for renaming. However, if
we detect an existing declaration with the same body from a previously
processed file, we reuse it.

\item In rare situations, it can happen that a file-local global in
encountered first and it is not renamed, only to discover later when
processing another file that there is an external symbol with the same name.
In this case, a second pass is made over the merged file to rename the
file-local symbol. 
\end{itemize}


    \section{Using the patcher}\label{sec-patcher}

 Occasionally we have needed to modify slightly the standard include files.
So, we developed a simple mechanism that allows us to create modified copies
of the include files and use them instead of the standard ones. For this
purpose we specify a patch file and we run a program caller that Patcher which
makes modified copies of include files and applies the patch.

 The patcher is invoked as follows: 
\begin{verbatim}
perl lib/patcher.pl [options]

Options:
  --help       Prints this help message
  --verbose    Prints a lot of information about what is being done
  --mode=xxx   What tool to emulate: 
                GNUCC     - GNU CC
                MSVC      - MS VC cl compiler

  --dest=xxx   The destination directory. Will make one if it does not exist
  --patch=xxx  Patch file (can be specified multiple times)
  --ppargs=xxx An argument to be passed to the preprocessor (can be specified
               multiple times)

  --ufile=xxx  A user-include file to be patched (treated as \#include "xxx")
  --sfile=xxx  A system-include file to be patched (treated as \#include <xxx>)
 
  --clean       Remove all files in the destination directory
  --dumpversion Print the version name used for the current compiler

 All of the other arguments are passed to the preprocessor.
\end{verbatim}

 Based on the given \t{mode} and the current version of the compiler (which
the patcher can print when given the \t{dumpversion} argument) the patcher
will create a subdirectory of the \t{dest} directory (say \t{/usr/home/necula/cil/include}), such as:
\begin{verbatim}
/usr/home/necula/cil/include/gcc_2.95.3-5
\end{verbatim}

 In that file the patcher will copy the modified versions of the include files
specified with the \t{ufile} and \t{sfile} options. Each of these options can
be specified multiple times. 

 The patch file (specified with the \t{patch} option) has a format inspired by
the Unix \t{patch} tool. The file has the following grammar:

\begin{verbatim}
<<< flags
patterns
===
replacement
>>>
\end{verbatim}

 The flags are a comma separated, case-sensitive, sequence of keywords or
keyword = value. The following flags are supported:
\begin{itemize}
\item \t{file=foo.h} - will only apply the patch on files whose name is
                       \t{foo.h}. 
\end{itemize}


 The patterns can consist of several groups of lines separated by the \t{|||}
marker. Each of these group of lines is a multi-line pattern that if found in
the file will be replaced with the text given at the end of the block. 

 The matching is space-insenstive.

 All of the markers \t{<<<}, \t{|||}, \t{===} and \t{>>>} must appear at the
beginning of a line but they can be followed by arbitrary text (which is
ignored).

 The replacement text can contain the special keyword \t{@\_\_pattern\_\_@},
which is substituted with the pattern that matched. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
\section{Using attributes with CIL}\label{sec-attrib}

 In CIL you can attach attributes to types and to names (variables, functions
and fields). The following syntax of attributes is currently supported: 

\begin{verbatim}
 attribute ::= IDENT | IDENT ( [attrarg ,]+ )
 attrarg   ::= IDENT | IDENT ( [attrarg ,]+) | "STRING" | INT
             | attrarg binop attrarg | unop attrarg
             | sizeof attrarg | sizeof type
\end{verbatim}

 The attribute names (IDENT above) must start with a letter and should not
start or end with underscore.

 The attributes are specified in declarations. This is unfortunate since the C
syntax for declarations is already quite complicated and after writing the
parser and elaborator for declarations I am convinced that few C programmers
understand it completely. Anyway, this seems to be the easiest way to support
attributes. 

 Name attributes must be specified at the very end of the declaration, just
before the = for the initializer or before the , the separates a declaration
in a group of declarations or just before the ; that terminates the
declaration. A name attribute for a function being defined can be specified
just before the brace that starts the function body. 

 For example (in the following examples A1,...,An are type attributes and N
  is a name attribute. We'll talk soon about how these attributes can be
  written in the source program): 

\begin{verbatim}
 int x N1;
 int x Nx, * y Ny = 0, z[] Nz;
 extern void exit() N;
 int fact(int x) N { ... }
\end{verbatim}


 Type attributes can be specified along with the type using the following
 rules: 
\begin{enumerate}
 \item The type attributes for a base type (int, float, named type, reference
    to struct or union or enum) must be specified immediately following the
    type (actually it is Ok to mix attributes with the specification of the
    type, in between unsigned and int for example).

  For example:
\begin{verbatim}
  int A1 x N1;  /* A1 applies to the type int. An example is an attribute
                   "even" restricting the type int to even values. */
  struct foo A1 A2 x; // Both A1 and A2 apply to the struct foo type
\end{verbatim}
 
 \item The type attributes for a pointer type must be specified immediately
 after the * symbol.
\begin{verbatim}
 /* A pointer (A1) to an int (A2) */
 int A2 * A1 x;
 /* A pointer (A1) to a pointer (A2) to a float (A3) */
 float A3 * A2 * A1 x;
\end{verbatim}


 Note: The attributes for base types and for pointer types are a strict
 extension of the ANSI C type qualifiers (const, volatile and restrict). In
 fact the is special support to parse these qualifiers as attributes. 

  \item The attributes for a function type or for an array type can be
     specified using parenthesized declarators.

   For example:
\begin{verbatim}
   /* A function (A1) from int (A2) to float (A3) */
   float A3 (A1 f)(int A2);

   /* An array (A1) of int (A2) */
   int A2 (A1 x0)[]

   /* Array (A1) of pointers (A2) to functions (A3) that take an int (A4) and 
    * return a pointer (A5) to int (A6)  */
   int A6 * A5 (A3 * A2 (A1 x1)[5])(int A4);


   /* A function (A4) that takes a float (A5) and returns a pointer (A6) to an 
    * int (A7) */
   extern int A7 * A6 (A4 x2)(float A5 x);

   /* A function (A1) that takes a int (A2) and that returns a pointer (A3) to 
    * a function (A4) that takes a float (A5) and returns a pointer (A6) to an 
    * int (A7) */
   int A7 * A6 (A4 * A3 (A1 x3)(int A2 x))(float A5) {
      return & x2;
   }
\end{verbatim}

\end{enumerate}

 Note: ANSI C does not allow the specification of type qualifiers for function
and array types, although it allows for the parenthesized declarator. With
just a bit of thought (looking at the first few examples above) I hope that
the placement of attributes for function and array types will seem intuitive.

 This extension is not without problems however. If you want to refer just to
a type (in a cast for example) then you leave the name out. But this leads to
strange conflicts due to the parentheses that we introduce to scope the
attributes. Take for example the type of x0 from above. It should be written
as: 
 
\begin{verbatim}
        int A2 (A1 )[]
\end{verbatim}

 But this will lead most C parsers into deep confusion because the parentheses
around A1 will be confused for parentheses of a function designator. To push
this problem around (I don't know a solution) whenever we are about to print a
parenthesized declarator with no name but with attributes, we comment out the
attributes so you can see them (for whatever is worth) without confusing the
compiler. For example, here is how we would print the above type:

\begin{verbatim}
        int A2 /*(A1 )*/[]
\end{verbatim}

 
 \subsection{Source-level representation of attributes}

 GCC already has extensive support for attributes, so we are going to extend
it to handle arbitrary attributes. A GCC attribute has the syntax:
 
\begin{verbatim}
 gccattribute ::= __attribute__((attribute))    (Note the double parentheses)
\end{verbatim}

 Since GCC and MSVC both support various flavors of each attribute (with or
without leading or trailing \_) we first strip ALL leading and trailing \_ from
the attribute name (the IDENT in the non-terminal "attribute", but not the
IDENT in the attribute arguments "attrarg"). When we print attributes, for GCC
we add two leading and two trailing \_; for MSVC we add just two leading \_.
 
 There is support in CIL so that you can control the printing of attributes.
This custom-printing support is now used to print the "const" qualifier as
"\t{const}" and not "\t{\_\_attribute\_\_((const))}". 


 \subsection{Handling of predefined GCC attributes}

 GCC already supports attributes in a lot of places in declarations. The only
place where we support attributes and GCC does not is right before the \{ that
starts a function body. 

 GCC classifies its attributes in attributes for functions, for variables and
for types, although the latter category is only usable in definition of struct
or union types and is not nearly as powerful as the CIL type attributes. We
have made an effort to reclassify GCC attributes in name and type attributes
(they only apply for function types). Here is what we came up with:

\begin{itemize}
  \item GCC name attributes:
   
   section, constructor, destructor, unused, weak, no\_instrument\_function,
   noreturn, alias, no\_check\_memory\_usage, dllinport, dllexport, exception,
   model

      Note: the "noreturn" attribute would be more appropriately qualified as a
      function type attribute. But we classify it as a name attribute to make
      it easier to support a similarly named MSVC attribute. 
  
  \item GCC function type attributes:

    fconst (printed as "const"), format, regparm, stdcall,
    cdecl, longcall

  I was not able to completely decipher the position in which these attributes
  must go. So, the CIL elaborator knows these names and applies the following
  rules: 
  \begin{itemize}
  \item All of the name attributes that appear anywhere in the declaration are
  collected and associated with the declared name. This was easy since each
  declaration declares exactly one name.

  \item More complicated is the handling of the function type attributes, since
     there can be more than one function in a single declaration (a function
     returning a pointer to a function). Lacking any real understanding of how
     GCC handles this, I attach the function type attribute to the "nearest"
     function. This means that if a pointer to a function is "nearby" the
     attribute will be correctly associated with the function. In truth I pray
     that nobody uses declarations as that of x3 above. 
  \end{itemize}
\end{itemize}

\subsection{Handling of predefined MSVC attributes}

  MSVC has two kinds of attributes, declaration modifiers to be printed before
  the storage specifier using the notation "\t{\_\_declspec(...)}" and a few
  function type attributes, printed almost as our CIL function type
  attributes. 

   The following are the name attributes that are printed using
   \t{\_\_declspec} right before the storage designator of the declaration:
   thread, naked, dllimport, dllexport, noreturn


   The following are the function type attributes supported by MSVC: 
   fastcall, cdecl, stdcall

   It is not worth going into the obscure details of where MSVC accepts these
   type attributes. The parser thinks it knows these details and it pulls
   these attributes from whereever they might be placed. The important thing
   is that MSVC will accept if we print them according to the rules of the CIL
   attributes ! 

\section{Who Says C is Simple?}\label{sec-simplec}

 When I (George) started to write CIL I thought it was going to take two weeks.
Exactly a year has passed since then and I am still fixing bugs in it. This
gross underestimate was due to the fact that I thought parsing and making
sense of C is simple. You probably think the same. What I did not expect was
how many dark corners this language has, especially if you want to parse
real-world programs such as those written for GCC or if you are more ambitious
and you want to parse the Linux or Windows NT sources (both of these were
written without any respect for the standard and with the expectation that
compilers will be changed to accomodate the program). 

 The following examples were actually encountered either in real programs or
are taken from the ISO C99 standard or from the GCC's testcases. My first
reaction when I saw these was: {\em Is this C?}. The second one was : {\em
What the hell does it mean?}. 

 If you are contemplating doing program analysis for C on abstract-syntax
trees then your analysis ought to be able to handle these things. Or, you can
use CIL and let CIL translate them into clean C code. 

%
% Note: the cilcode environment is bogus. You should preprocess this source
% with cilcode.pl !!!
%
%
 \subsection{Standard C}

\begin{enumerate}

\item Why does the following code return 0 for most values of \t{x}? (This
should be easy.)

\begin{cilcode}[local]
  int x;
  return x == (1 && x);
\end{cilcode}

\item Why does the following code return 0? (Answer: because \t{sizeof} is
unsigned, thus the result of the subtraction is unsigned, thus the shift is logical.)

\begin{cilcode}[local]
 return ((1 - sizeof(int)) >> 4);
\end{cilcode}

\item Scoping rules can be tricky. This function returns 5.

\begin{cilcode}[global]
int x = 5;
int f() {
  int x = 3;
  {
    extern int x;
    return x;
  }
}
\end{cilcode}

\item Functions and function pointers are implicitly converted to each other. 

\begin{cilcode}[global]
int (*pf)(void);
int f(void) {

   *pf = f; // This looks ok
   pf(); // Invoke a function pointer?     
   ****pf = f; // Looks strange but Ok
   ****pf = *********f; // Looks strange but Ok
   (***************f)(); // Also Ok             
}
\end{cilcode}

\item Initializer with designators are one of the hardest parts about ISO C.
Neither MSVC or GCC implement them fully. GCC comes close though. What is the
final value of \t{i.nested.y} and \t{i.nested.z}? (Answer: 2 and respectively
6). 

\begin{cilcode}[global]
struct { 
   int x; 
   struct { 
       int y, z; 
   } nested;
} i = { .nested.y = 5, 6, .x = 1, 2 };               
\end{cilcode}

\item This is from c-torture. This function returns 1.

\begin{cilcode}[global]
typedef struct
{
  char *key;
  char *value;
} T1;

typedef struct
{
  long type;
  char *value;
} T3;

T1 a[] =
{
  {
    "",
    ((char *)&((T3) {1, (char *) 1}))
  }
};
int main() {
   T3 *pt3 = (T3*)a[0].value;
   return pt3->value;
}
\end{cilcode}

\item Another one with constructed literals. This one would not go through GCC
(but goes through CIL). This code returns 2.

\begin{cilcode}[local]
 return ((int []){1,2,3,4})[1];
\end{cilcode}

\end{enumerate}

 \subsection{GCC ugliness}

\begin{enumerate}

\item GCC has generalized lvalues. You can take the address of a lot of
strange things:

\begin{cilcode}[local]
  int x, y, z;
  return &(x ? y : z) - & (x++, x);
\end{cilcode}

\item GCC lets you omit the second component of a conditional expression.

\begin{cilcode}[local]
  extern int f();
  return f() ? : -1; // Returns the result of f unless it is 0
\end{cilcode}

\item Computed jumps can be tricky. CIL compiles them away in a fairly clean
way but you are on your own if you try to jump into another function this way.

\begin{cilcode}[global]
static void *jtab[2];
static int doit(int x){
 
  static int jtab_init = 0;
  if(!jtab_init) {
    jtab[0] = &&lbl1;
    jtab[1] = &&lbl2;
    jtab_init = 1;
  }
  goto *jtab[x];
lbl1:
  return 0;
lbl2:
  return 1;
}
 
int main(void){
  if (doit(0) != 0) exit(1);
  if (doit(1) != 1) exit(1);
  exit(0);
}
\end{cilcode}


\item A cute little example that we made up. What is the returned value?
(Answer: 1); 
\begin{cilcode}[local]
 return ({goto L; 0;}) && ({L: 5;});
\end{cilcode}

\item \t{extern inline} is a strange feature of C. Can you guess what the
following code computes? 

\begin{cilcode}[global]
extern inline foo(void) { return 1; }
int firstuse(void) { return foo(); }

// A second, incompatible definition of foo
int foo(void) { return 2; }

int main() {
    return foo() + firstuse();
}
\end{cilcode}

 The answer depends on whether the optimizations are turned on. If they are
then the answer is 3 (the first definition is inlined at all occurrences until
the second definition). If the optimizations are off, then the first
definition is ignore (treated like a prototype) and the answer is 4. 

 CIL will misbehave on this example, if the optimizations are turned off (it
 always returns 3).

\item GCC allows you to cast an object of a type T into a union as long as the
union has a field of that type:
\begin{cilcode}[global]
union u { 
   int i; 
   struct s { 
      int i1, i2;
   } s;
};

union u x = (union u)6;

int main() {
  struct s y = {1, 2};
  union u  z = (union u)y;
}
\end{cilcode}

\end{enumerate}

 \subsection{Microsoft VC ugliness}

 This compiler has few extensions, so there is not much to say here.

\begin{enumerate}
\item Why does the following code return 0 and not -1? (Answer: because of a bug in
Microsoft Visual C. It thinks that the shift is unsigned just because the
second operator is unsigned. CIL reproduces this bug for MSVC.)

\begin{verbatim}
 return -3 >> (8 * sizeof(int));
\end{verbatim}

\item Unnamed fields in a structure seem really strange at first. It seems
that Microsoft Visual C introduced this extension, then GCC picked it up (but
in the process implemented it wrongly: in GCC the field \t{y} overlaps with \t{x}!).

\begin{cilcode}[local]
struct {
  int x;
  struct {
     int y, z;
     struct {
       int u, v;
     };
 };
} a;
return a.x + a.y + a.z + a.u + a.v;
\end{cilcode}


\end{enumerate}

\section{Credits}

 CIL was develped starting from Hugues Casse's \t{frontc} front-end for C
although all the files from the \t{frontc} distribution have been changed very
extensively. The main author is George Necula, with significant contributions
from Scott McPeak, Westley Weimer, Raymond To and Aman Bhargava.
 
\end{document}



