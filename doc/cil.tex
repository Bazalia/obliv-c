\documentclass{article}
\usepackage{hevea}
% cilversion.tex is generated automatically to define \cilversion
\include{cil.version}

\def\secref#1{Section~\ref{sec-#1}}
\def\chref#1{Chapter~\ref{ch-#1}}

\def\apiref#1#2#3{\ahref{api/#1.html\##2#3}{#1.#3}}
\def\moduleref#1{\ahref{api/#1.html}{#1}}

% Use this to refer to a Cil type/val
\def\ciltyperef#1{\apiref{Cil}{TYPE}{#1}}
\def\cilvalref#1{\apiref{Cil}{VAL}{#1}}
\def\formatcilvalref#1{\apiref{Formatcil}{VAL}{#1}}
\def\cilvisit#1{\apiref{Cil.cilVisitor}{#1}}
\def\cilprinter#1{\apiref{Cil.cilPrinter}{#1}}

% Use this to refer to a type/val in the Pretty module
\def\ptyperef#1{\apiref{Pretty}{TYPE}{#1}}
\def\pvalref#1{\apiref{Pretty}{VAL}{#1}}

% Use this to refer to a type/val in the Errormsg module
\def\etyperef#1{\apiref{Errormsg}{TYPE}{#1}}
\def\evalref#1{\apiref{Errormsg}{VAL}{#1}}

%----------------------------------------------------------------------
% MACROS

\newcommand{\hsp}{\hspace{0.5in}}
\def\t#1{{\tt #1}}
\newcommand\codecolor{\ifhevea\blue\else\fi}
\renewcommand\c[1]{{\codecolor #1}} % Use for code fragments

%%% Define an environment for code
%% Unfortunately since hevea is not quite TeX you have to use this as follows
%\begin{code}
% ...
%\end{verbatim}\end{code}
\def\code{\begingroup\codecolor\begin{verbatim}}
\def\endcode{\endgroup}

%----------------------------------------------------------------------

% Make sure that all documents show up in the main frame
%HEVEA \AtBeginDocument{\@print{<base target="main">}}

\begin{document}
\maketitle

\section{Introduction}

 CIL ({\bf C} {\bf I}ntermediate {\bf L}anguage) is a high-level representation
along with a set of tools that permit easy analysis and source-to-source
transformation of C programs.

 CIL is both lower-level than abstract-syntax trees, by clarifying ambiguous
constructs and removing redundant ones, and also higher-level than typical
intermediate languages designed for compilation, by maintaining types and a
close relationship with the source program. The main advantage of CIL is that
it compiles all valid C programs into a few core constructs with a very clean
semantics. Also CIL has a syntax-directed type system that makes it easy to
analyze and manipulate C programs. Furthermore, the CIL front-end is able to
process not only ANSI-C programs but also those using Microsoft C or GNU C
extensions. If you do not use CIL and want instead to use just a C parser and
analyze programs expressed as abstract-syntax trees then your analysis will
have to handle a lot of ugly corners of the language (let alone the fact that
parsing C itself is not a trivial task). See \secref{simplec} for some
examples of such extreme programs that CIL simplifies for you.

 In essence, CIL is a highly-structured, ``clean'' subset of C. CIL features a
reduced number of syntactic and conceptual forms. For example, all looping
constructs are reduced to a single form, all function bodies are given
explicit {\tt return} statements, syntactic sugar like {\tt "->"} is
eliminated and function arguments with array types become pointers. (For an
extensive list of how CIL simplifies C programs, see \secref{cabs2cil}.)
This reduces the number of cases that must be considered when manipulating a C
program. CIL also separates type declarations from code and flattens scopes
within function bodies. This structures the program in a manner more amenable
to rapid analysis and transformation. CIL computes the types of all program
expressions, and makes all type promotions and casts explicit. CIL supports
all GCC and MSVC extensions except for nested functions and complex numbers.
Finally, CIL organizes C's imperative features into expressions, instructions
and statements based on the presence and absence of side-effects and
control-flow. Every statement can be annotated with successor and predecessor
information. Thus CIL provides an integrated program representation that can
be used with routines that require an AST (e.g. type-based analyses and
pretty-printers), as well as with routines that require a CFG (e.g., dataflow
analyses).

 CIL comes accompanied by a number of Perl scripts that perform generally
useful operations on code:
\begin{itemize}
\item A \ahrefloc{sec-driver}{driver} which behaves as either the \t{gcc} or
Microsoft VC compiler and can invoke the preprocessor followed by the CIL
application. The advantage of this script is that you can easily use CIL and
the analyses written for CIL with existing make files.
\item A \ahrefloc {sec-merger}{whole-program merger} that you can use as a
replacement for your compiler and it learns all the files you compile when you
make a project and merges all of the preprocessed source files into a single
one. This makes it easy to do whole-program analysis.
\item A \ahrefloc{sec-patcher}{patcher} makes it easy to create modified
copies of the system include files. The CIL driver can then be told to use
these patched copies instead of the standard ones.
\end{itemize}

 CIL has been tested very extensively. It is able to process the SPECINT95
benchmarks, the Linux kernel, GIMP and other open-source projects. All of
these programs are compiled to the simple CIL and then passed to \t{gcc} and
they still run! We consider the compilation of Linux a major feat especially
since Linux contains many of the ugly GCC extensions (see \secref{ugly-gcc}).
This adds to about 1,000,000 lines of code that we tested it on. It is also
able to process the few Microsoft NT device drivers that we have had access
to. CIL was tested against GCC's c-torture testsuite and (except for the tests
involving complex numbers and inner functions, which CIL does not currently
implement) CIL passes most of the tests. Specifically CIL fails 23 tests out
of the 904 c-torture tests that it should pass. GCC itself fails 19 tests. A
total of 1400 regression test cases are run automatically on each change to
the CIL sources.

 CIL is relatively independent on the underlying machine and compiler. When
you build it CIL will configure itself according to the underlying compiler.
However, CIL has only been tested on Intel x86 using the gcc compiler on Linux
and cygwin and using the MS Visual C compiler. (See below for specific
versions of these compilers that we have used CIL for.)

 The largest application we have used CIL for is
\ahref{../ccured/index.html}{CCured}, a compiler that compiles C code into
type-safe code by analyzing your pointer usage and inserting runtime checks in
the places that cannot be guaranteed statically to be type safe.  

 You can also use CIL to ``compile'' code that uses GCC extensions (e.g. the
Linux kernel) into standard C code.

\section{Installation}

You will need OCaml release 3.04 or higher to build CIL (we have tested it
with 3.05 and 3.06 as well). CIL has been tested on Linux and on Windows
(where it can behave at either Microsoft Visual C or gcc).

 If you want to use CIL on Windows then you must get a complete installation
of \t{cygwin} and the source-code OCaml distribution and compile it yourself
using the cygwin tools (as opposed to getting the Win32 native-code version of
OCaml). If you have not done this before then take a look
\ahref{../ccured/setup.html}{here}. (Don't need to worry about \t{cvs} and
\t{ssh} unless you will need to use the master CVS repository for CIL.)

\begin{enumerate}
\item Download the CIL \ahref{distrib}{distribution} (latest version is
\ahrefurl{distrib/cil-\cilversion.tar.gz}). See the \secref{changes} for recent changes to the CIL distribution.
\item Unzip and untar the source distribution. This will create a directory
      called \t{cil} whose structure is explained below. \\
      \t{tar xvfz cil-\cilversion.tar.gz}
\item Enter the \t{cil} directory and run the \t{configure} script and then 
      GNU make to build the distribution. If you are on Windows, at least the
      \t{configure} step must be run from within \t{bash}. \\
      \hsp\verb!cd cil!\\
      \hsp\verb!./configure!\\
      \hsp\verb!make!\\
      \hsp\verb!make quicktest!\\

\item You should now find \t{cilly.asm.exe} and \t{merger.asm.exe} in a
subdirectory of \t{obj}. The name of the subdirectory is either \t{x86\_WIN32}
if you are using \t{cygwin} on Windows or \t{x86\_LINUX} if you are using
Linux (although you should be using instead the Perl wrapper \t{bin/cilly}).
Note that we do not have an \t{install} make target and you should use Cil
from the development directory. 
\item If you decide to use CIL, {\bf please}
\ahref{mailto:necula@cs.berkeley.edu}{send us a note}. This will help recharge
our batteries after more than a year of development. And of course, do send us
your bug reports as well.

\end{enumerate}

 The \t{configure} script tries to find appropriate defaults for your system.
You can control its actions by passing the following arguments:
\begin{itemize}
\item \t{CC=foo} Specifies the path for the \t{gcc} executable. By default
whichever version is in the PATH is used.
\end{itemize}

 CIL requires an underlying C compiler and preprocessor. CIL depends on the
underlying compiler and machine for the sizes and alignment of types.The
installation procedure for CIL queries the underlying compiler for
architecture and compiler dependent configuration parameters, such as the size
of a pointer or the particular alignment rules for structure fields. (This
means, of course, that you should re-run \t{./configure} when you move CIL to
another machine.)

% CIL also depends on how the compiler implements the variable argument
%functions. 
%Most notably, {\bf Note: CIL does not work with gcc version 2.96
%because of the way in which it implements varargs.}. You should not use
%version 2.96 because \ahref{http://gcc.gnu.org/gcc-2.96.html}{it was not a
%formal gcc release}, just a (buggy) developement version. You should upgrade
%your gcc to version 3.2 or to 2.95.3 (which actually appears to be much faster
%than 3.2). We have tested CIL on the following compilers:

\begin{itemize}
\item On Windows, \t{cl} compiler version 12.00.8168 and 13.00.9466. 
Run \t{cl} with no arguments to get the compiler version. 
\item On Windows, using \t{cygwin} and \t{gcc} version 2.95.3, 3.0 and 3.2.
\item On Linux, using \t{gcc} version 2.95.3, 3.0 and 3.2.
\end{itemize}

The file \ahrefurl{distrib/cil-\cilversion.tar.gz} 
contains the complete source CIL distribution, 
consisting of the following files:

\begin{tabular}{ll}
Filename   & Description \\
\t{Makefile}                    & Just a little wrapper for \t{Makefile.cil} \\
\t{Makefile.cil.in}              & \t{configure} source for the 
                                  Makefile for building CIL \\
\t{configure}                   & The configure script \\
\t{configure.in}                & The \t{autoconf} source for \t{configure} \\
\t{config.guess}, \t{config.sub}, \t{install-sh} & stuff required by
                                \t{configure} \\
\t{Makefile.ocaml}              & A file that is included by \t{Makefile} \\
\t{Makefile.ocaml.build}        & A file that is included by \t{Makefile} \\
\t{doc/}                        & HTML documentation of the CIL API \\
\t{obj/}                        & Directory that will contain the compiled
                                   CIL modules and executables\\
\t{bin/cilly.in}                & The \t{configure} source for a Perl script 
                                  that can be invoked with the 
                                  same arguments as either \t{gcc} or
                                  Microsoft Visual C and will convert the
                                  program to CIL, perform some simple
                                  transformations, emit it and compile it as
                                  usual. \\
\t{lib/CompilerStub.pm}         & A Perl class that can be used to write code
                                  that impersonates a compiler. \t{cilly}
                                  uses it.  \\
\t{lib/Merger.pm}               &  A subclass of \t{CompilerStub.pm} that can
                                  be used to merge source files into a single
                                  source file.\t{cilly}
                                  uses it. \\
\t{bin/patcher.in}              & A Perl script that applies specified patches
                                  to standard include files.\\
\t{src/check.ml,mli}            & Checks the well-formedness of a CIL file \\
\t{src/cil.ml,mli}              & Definition of CIL abstract syntax and
                                   utilities for manipulating it\\
\t{src/clist.ml,mli}            & Utilities for efficiently managing lists
                                   that need to be concatenated often\\
\t{src/errormsg.ml,mli}         & Utilities for error reporting \\
\t{src/ext/heapify.ml}          & A CIL transformation that moves array local
                                   variables from the stack to the heap \\
\t{src/ext/logcalls.ml,mli}     & A CIL transformation that logs every
                                   function call \\
\t{src/ext/logwrites.ml}        & A CIL transformation that logs every memory
                                   write \\
\t{src/frontc/clexer.mll}       & The lexer \\
\t{src/frontc/cparser.mly}      & The parser \\
\t{src/frontc/cabs.ml}          & The abstract syntax \\
\t{src/frontc/cprint.ml}        & The pretty printer for CABS \\
\t{src/frontc/cabs2cil.ml}      & The elaborator to CIL \\
\t{src/maincil.ml}                 & A test application called \t{cilly} \\
\t{src/pretty.ml,mli}           & Utilities for pretty printing \\
\t{src/rmtmps.ml,mli}           & A CIL tranformation that removes unused
                                  types, variables and inlined functions \\
\t{src/stats.ml,mli}            & Utilities for maintaining timing statistics
\\
\t{src/testcil.ml}              & A random test of CIL (against the resident 
                                  C compiler)\\
\t{src/trace.ml,mli}            & Utilities useful for printing debugging
                                   information\\
\t{src/util.ml}                 & Miscellaneous functions and global variables
\end{tabular}


\section{Compiling C to CIL}\label{sec-cabs2cil}

 In this section we try to describe a few of the many transformations that are
applied to a C program to convert it to CIL. The module that implements this
conversion is about 5000 lines of OCaml code. In contrast a simple program
transformation that instruments all functions to keep a shadow stack of the
true return address (thus preventing stack smashing) is only 70 lines of code.
This example shows that the analysis is so much simpler because it has to
handle only a few simple C constructs and also because it can leverage on CIL
infrastructure such as visitors and pretty-printers.

 In no particular order these are a few of the most significant ways in which
C programs are compiled into CIL:
\begin{enumerate}
\item CIL will eliminate all declarations for unused entities. This means that
just because your hello world program includes \t{stdio.h} it does not mean
that your analysis has to handle all the ugly stuff from \t{stdio.h}.

\item Type specifiers are interpreted and normalized:
\begin{cilcode}[global]
int long signed x;
signed long extern x;
long static int long y;
\end{cilcode}

\item Anonymous structure and union declarations are given a name. 
\begin{cilcode}[global]
 struct { int x; } s;
\end{cilcode}

\item Nested structure tag definitions are pulled apart. This means that all
structure tag definitions can be found by a simple scan of the globals.

\begin{cilcode}[global]
struct foo {
   struct bar {
      union baz { 
          int x1; 
          double x2;
      } u1;
      int y;
   } s1;
   int z;
} f;
\end{cilcode}

\item All structure, union, enumeration definitions and the type definitions
from inners scopes are moved to global scope (with appropriate renaming). This
facilitates moving around of the references to these entities.

\begin{cilcode}[global]
int main() {
  struct foo { 
        int x; } foo; 
  {
     struct foo { 
        double d;
     };
     return foo.x;
  }      
}
\end{cilcode}

\item Prototypes are added for those functions that are called before being
defined. Furthermore, if a prototype exists but does not specify the type of
parameters that is fixed. But CIL will not be able to add prototypes for those
functions that are neither declared nor defined (but are used!).
\begin{cilcode}[global]
  int f();  // Prototype without arguments
  int f(double x) {
      return g(x);
  }
  int g(double x) {
     return x;
  } 
\end{cilcode}

\item Array lengths are computed based on the initializers or by constant
folding.
\begin{cilcode}[global]
  int a1[] = {1,2,3};
  int a2[sizeof(int) >= 4 ? 8 : 16];
\end{cilcode}

\item Enumeration tags are computed using constant folding:
\begin{cilcode}[global]
  enum { 
     FIVE = 5, 
     SIX, SEVEN, 
     FOUR = FIVE - 1, 
     EIGHT = sizeof(double)
  };
\end{cilcode}

\item Initializers are normalized to include specific initialization for the
missing elements:
\begin{cilcode}[global]
  int a1[5] = {1,2,3};
  struct foo { int x, y; } s1 = { 4 };
\end{cilcode}

\item Initializer designators are interpreted and eliminated. Subobjects are
properly marked with braces. CIL implements
the whole ISO C99 specification for initializer (neither GCC nor MSVC do) and
a few GCC extensions. 
\begin{cilcode}[global]
  struct foo { 
     int x, y; 
     int a[5];
     struct inner {
        int z;
     } inner;
  } s = { 0, .inner.z = 3, .a[1 ... 2] = 5, 4, y : 8 };
\end{cilcode}

\item String initializers for arrays of characters are processed

\begin{cilcode}[global]
char foo[] = "foo plus bar";
\end{cilcode}

\item String constants are concatenated

\begin{cilcode}[global]
char *foo = "foo " " plus " " bar ";
\end{cilcode}

\item Initializers for local variables are turned into assignments. This is in
order to separate completely the declarative part of a function body from the
statements. This has the unfortunate effect that we have to drop the \t{const}
qualifier from local variables !

\begin{cilcode}[local]
  int x = 5; 
  struct foo { int f1, f2; } a [] = {1, 2, 3, 4, 5 };
\end{cilcode}

\item Local variables in inner scopes are pulled to function scope (with
appropriate renaming). Local scopes thus disappear. This makes it easy to find
and operate on all local variables in a function.

\begin{cilcode}[global]
  int x = 5; 
  int main() {
    int x = 6;
    { 
      int x = 7;
      return x;
    }
    return x;
  } 
\end{cilcode}

\item Global declarations in local scopes are moved to global scope:
\begin{cilcode}[global]
  int x = 5; 
  int main() {
    int x = 6;
    { 
      static int x = 7;
      return x;
    }
    return x;
  } 
\end{cilcode}

\item Return statements are added for functions that are missing them. If the
return type is not a base type then a \t{return} without a value is added.
The guaranteed presence of return statements makes it easy to implement a
transformation that inserts some code to be executed immediately before
returning from a function.
\begin{cilcode}[global]
  int foo() {
    int x = 5;
  } 
\end{cilcode}

\item One of the most significant transformations is that expressions that
contain side-effects are separated into statements. 

\begin{cilcode}[local]
   int x, f(int);
   return (x ++ + f(x));
\end{cilcode}

 Internally, the \t{x ++} statement is turned into an assignment which the
pretty-printer prints like the original. CIL has only three forms of basic
statements: assignments, function calls and inline assembly.

\item Shortcut evaluation of boolean expressions and the \t{?:} operator are
compiled into explicit conditionals:
\begin{cilcode}[local]
  int x;
  int y = x ? 2 : 4;
  int z = x || y;
  // Here we duplicate the return statement
  if(x && y) { return 0; } else { return 1; }
  // To avoid excessive duplication, CIL uses goto's for 
  // statement that have more than 5 instructions
  if(x && y || z) { x ++; y ++; z ++; x ++; y ++; return z; }
\end{cilcode}

\item GCC's conditional expression with missing operands are also compiled
into conditionals:
\begin{cilcode}[local]
  int f();;
  return f() ? : 4;
\end{cilcode}

\item GCC's 

\item All forms of loops (\t{while}, \t{for} and \t{do}) are compiled
internally as a single \t{while(1)} looping construct with explicit \t{break}
statement for termination. For simple \t{while} loops the pretty printer is
able to print back the original:
\begin{cilcode}[local]
   int x, y;
   for(int i = 0; i<5; i++) {
      if(i == 5) continue;
      if(i == 4) break;
      i += 2;
   } 
   while(x < 5) {
     if(x == 3) continue;
     x ++;
   }
\end{cilcode}

\item GCC's block expressions are compiled away. (That's right there is an
infinite loop in this code.)

\begin{cilcode}[local]
   int x = 5, y = x;
   int z = ({ x++; L: y -= x; y;});
   return ({ goto L; 0; });
\end{cilcode}

\item CIL contains support for both MSVC and GCC inline assembly (both in one
internal construct)

\item CIL compiles away the GCC extension that allows many kinds of constructs
to be used as lvalues:

\begin{cilcode}[local]
   int x, y, z;
   return &(x ? y : z) - & (x ++, x);
\end{cilcode}

\item All types are computed and explicit casts are inserted for all
promotions and conversions that a compiler must insert:

\item CIL will turn old-style function definition (without prototype) into
new-style definitions. This will make the compiler less forgiving when
checking function calls, and will catch for example cases when a function is
called with too few arguments. This happens in old-style code for the purpose
of implementing variable argument functions. To make the code compile after
CIL we insert dummy arguments for the missing ones:
\begin{cilcode}[global]
#include <stdio.h>
int f(s1, s2) char *s1, *s2; {
  printf(s1, s2);
}

int main() {
    f("hello %s!\n", "world");
    f("hello again\n"); // f called with only one argument
}
\end{cilcode}
 
\item Since CIL sees the source after preprocessing the code after CIL does
not contain the comments and the preprocessing directives.

\item CIL will remove from the source file those type declarations, local
variables and inline functions that are not used in the file. This means that
your analysis does not have to see all the ugly stuff that comes from the
header files: 
\begin{cilcode}[global]
#include <stdio.h>

typedef int unused_type;

inline char unused_inline (void) { return 0; }

int main() {
  int unused_local;
  printf("Hello world\n"); // Only printf will be kept from stdio.h     
}
\end{cilcode}

\end{enumerate}

\section{Using CIL}\label{sec-cil}
 
 In order to use CIL you must write an Ocaml module containing your analysis
and transformation, which you then link into our boilerplate application
called cilly. An example of such module is \t{logwrites.ml} (a module that is
distributed with CIL and whose purpose is to instrument code to print the
addresses of memory locations being written). (We plan to release a C-language
interface to CIL so that you can write your analyses in C instead of Ocaml.)
Assuming that you have written \t{logwrites.ml} here is how you use it: 

 \begin{enumerate}
 \item Put \t{logwrites.ml} in the \t{src} directory. This will make sure that
 \t{make} can find it. If you want to put it in some other directory modify
 the \t{Makefile} and add to \t{SOURCEDIRS} your directory. 

 \item Modify the \t{Makefile} and add your module to the \t{MODULES}
 variable. The order of the modules matters. Add your modules somewhere after
 \t{cil} and before \t{maincil}.

 \item Modify \t{maincil.ml} and add descriptions of the new command line
 options that you want to add to \t{cilly}. This is done by modifying the
 definition of \t{argDescr} variable using the convention of the Ocaml
 standard library module \t{Arg}. For \t{logWrites} we added the option
 \t{--logwrites} that sets a global variable that enables the \t{logWrites}
 transformation.

 \item Modify \t{maincil.ml} add add a call to the top level function of your
 module to the body of the function \t{processOneFile}. Alternatively, you can
 call the \t{Frontc.parse: string -> unit -> Cil.file} function with the name
 of a file containing the output of the preprocessor and then invoke your
 analysis function on the resulting \t{Cil.file} data structure. You might
 want to call \t{Rmtmps.removeUnusedTemps} first to clean up the prototype and
 variables that are not used. Then you can call the function \t{Cil.printFile:
 cilPrinter -> out\_channel -> Cil.file -> unit} to print the file to a given
 output channel. A good \t{cilPrinter} to use is \t{defaultCilPrinter}. 

 \item In the \t{cil} directory run \t{make setup} to make both the bytecode
 and the native code versions of the \t{cilly} application (in
 \t{obj/cilly.byte.exe} and in \t{obj/cilly.asm.exe} respectively).

 \item Now you can invoke the \t{cilly} application on a preprocessed file, or
 instead use the \t{cilly} driver which provides a convenient compiler-like
 interface to \t{cilly}. See \secref{driver} for details using \t{cilly}.
 \end{enumerate}

 In the next section we give an overview of the API that you can use
to write your analysis and transformation. 
 
\section{CIL API Documentation}\label{sec-api} 

 The CIL API is documented in the file \t{src/cil.mli}. We also have an
\ahref{api/index.html}{online documentation} extracted from \t{cil.mli}. We
index below the main types that are used to represent C programs in CIL: 

\begin{itemize}
\item \ahref{api/index\_types.html}{An index of all types}
\item \ahref{api/index\_values.html}{An index of all values}
\item \ciltyperef{file} is the representation of a file.
\item \ciltyperef{global} is the representation of a global declaration or
definitions. Values for \ahref{api/Cil.html\#VALemptyFunction}{operating on globals}.
\item \ciltyperef{typ} is the representation of a type.  
Values for \ahref{api/Cil.html\#VALvoidType}{operating on types}.
\item \ciltyperef{compinfo} is the representation of a structure or a union
type
\item \ciltyperef{fieldinfo} is the representation of a field in a structure
or a union
\item \ciltyperef{enuminfo} is the representation of an enumeration type. 
\item \ciltyperef{varinfo} is the representation of a variable 
\item \ciltyperef{fundec} is the representation of a function
\item \ciltyperef{lval} is the representation of an lvalue.
Values for \ahref{api/Cil.html\#VALmakeVarInfo}{operating on lvalues}.
\item \ciltyperef{exp} is the representation of an expression without
side-effects. 
Values for \ahref{api/Cil.html\#VALzero}{operating on expressions}.
\item \ciltyperef{instr} is the representation of an instruction (with
side-effects but without control-flow)
\item \ciltyperef{stmt} is the representation of a control-flow statements. 
Values for \ahref{api/Cil.html\#VALmkStmt}{operating on statements}.
\item \ciltyperef{attribute} is the representation of attributes. 
Values for \ahref{api/Cil.html\#TYPEattributeClass}{operating on attributes}.
\end{itemize}


 \subsection{Using the visitor}\label{sec-visitor}

 One of the most useful tools exported by the CIL API is an implementation of
the visitor pattern for CIL programs. The visiting engine scans depth-first
the structure of a CIL program and at each node is queries a user-provided
visitor structure whether it should do one of the following operations: 
\begin{itemize}
\item Ignore this node and all its descendants
\item Descend into all of the children and when done rebuild the node if any
of the children have changed. 
\item Replace the subtree rooted at the node with another tree.
\item Replace the subtree with another tree, then descend into the children
and rebuild the node if necessary and then invoke a user-specified function. 
\item In addition to all of the above actions then visitor can specify that
some instructions should be queued to be inserted before the current
instruction or statement being visited. 
\end{itemize}

 By writing visitors you can customize the program traversal and
transformation. One major limitation of the visiting engine is that it does
not propagate information from one node to another. Each visitor must use its
own private data to achieve this effect if necessary. 

 Each visitor is an object that is an instance of a class of type \cilvisit{}.
The most convenient way to obtain such classes is to specialize the
\apiref{Cil.nopCilVisitor}{} class (which just traverses the tree doing
nothing). Any given specialization typically overrides only a few of the
methods. Take a look for example at the visitor defined in the module
\t{logwrites.ml}. Another, more elaborate example of a visitor is the
[copyFunctionVisitor] defined in \t{cil.ml}.

 Once you have defined a visitor you can invoke it with one of the functions:
\begin{itemize}
\item \cilvalref{visitCilFile} or \cilvalref{visitCilFileSameGlobals} - visit a file
\item \cilvalref{visitCilGlobal} - visit a global
\item \cilvalref{visitCilFunction} - visit a function definition
\item \cilvalref{visitCilExp} - visit an expression
\item \cilvalref{visitCilLval} - visit an lvalue
\item \cilvalref{visitCilInstr} - visit an instruction
\item \cilvalref{visitCilStmt} - visit a statement
\item \cilvalref{visitCilType} - visit a type. Note that this does not visit
the files of a composite type. use visitGlobal to visit the [GCompTag] that
defines the fields.
\end{itemize}

Some transformations may want to use visitors to insert additional
instructions before statements and instructions. To do so, pass a list of
instructions to the  \cilvalref{queueInstr} method of the specialized
object. The instructions will automatically be inserted before that
instruction in the transformed code. The \cilvalref{unqueueInstr} method
should not normally be called by the user. 

 \subsection{Interpreted Constructors and Deconstructors}

 Interpreted constructors and deconstructors are a facility for constructing
and deconstructing CIL constructs using a pattern with holes that can be
filled with a variety of kinds of elements. The pattern is a string that uses
the C syntax to represent C language elements. For example, the following
code:
\begin{code}
Formatcil.cType "void * const (*)(int x)"
\end{verbatim}\end{code}

 is an alternative way to construct the internal representation of the type of pointer to function
with an integer argument and a {void * const} as result: 
\begin{code}
TPtr(TFun(TVoid [Attr("const", [])],
          [ ("x", TInt(IInt, []), []) ], false, []), [])
\end{verbatim}\end{code}

 The advantage of the interpreted constructors is that you can use familiar C
syntax to construct CIL abstract-syntax trees. 

 You can construct this way types, lvalues, expressions, instructions and
statements. The pattern string can also contain a number of placeholders that
are replaced during construction with CIL items passed as additional argument
to the construction function. For example, the \t{\%e:id} placeholder means
that the argument labeled ``id'' (expected to be of form \t{Fe exp}) will
supply the expression to replace the placeholder. For example, the following
code constructs an increment instruction:
\begin{code}
Formatcil.cInstr "%v:x = %v:x + %e:something"
        [ ("something", Fe some_exp);
          ("x", Fv some_varinfo) ]
\end{verbatim}\end{code}

 An alternative way to construct the same CIL instruction is:
\begin{code}
Set((Var some_varinfo, NoOffset),
    BinOp(PlusA, Lval (Var some_varinfo, NoOffset),
          some_exp, intType))
\end{verbatim}\end{code}

 See \ciltyperef{formatArg} for a definition of the placeholders that are
understood.

 A dual feature is the interpreted deconstructors. This can be used to test
whether a CIL construct has a certain form:
\begin{code}
Formatcil.dType "void * const (*)(int x)" t
\end{verbatim}\end{code}

 will test whether the actual argument \t{t} is indeed a function pointer of
the required type. If it is then the result is \t{Some []} otherwise it is
\t{None}. Furthermore, for the purpose of the interpreted deconstructors
placeholders in patterns match anything of the right type. For example, 
\begin{code}
Formatcil.dType "void * (*)(%F:t)" t
\end{verbatim}\end{code}

 will match any function pointer type, independent of the type and number of
the formals. If the match succeeds the result is \t{Some [ FF forms ]} where
\t{forms} is a list of names and types of the formals. Note that each member
in the resulting list corresponds positionally to a placeholder in the
pattern.

 The interpreted constructors and deconstructors do not support the complete C
syntax, but only a substantial fragment chosen to simplify the parsing. The
following is the syntax that is supported:
\begin{verbatim}
Expressions:
  E ::= %e:ID | %d:ID | %g:ID | n | L | ( E ) | Unop E | E Binop E 
        | sizeof E | sizeof ( T ) | alignof E  | alignof ( T ) 
        | & L | ( T ) E 

Unary operators:
  Unop ::= + | - | ~ | %u:ID

Binary operators:
  Binop ::= + | - | * | / | << | >> | & | ``|'' | ^ 
          | == | != | < | > | <= | >= | %b:ID

Lvalues:
  L ::= %l:ID | %v:ID Offset | * E | (* E) Offset | E -> ident Offset 

Offsets:
  Offset ::= empty | %o:ID | . ident Offset | [ E ] Offset

Types:
  T ::= Type_spec Attrs Decl

Type specifiers:
  Type_spec ::= void | char | unsigned char | short | unsigned short
            | int | unsigned int | long | unsigned long | %k:ID | float 
            | double | struct %c:ID | union %c:ID 


Declarators:
  Decl ::= * Attrs Decl | Direct_decl


Direct declarators:
  Direct_decl ::= empty | ident | ( Attrs Decl ) 
                 | Direct_decl [ Exp_opt ]
                 | ( Attrs Decl )( Parameters )

Optional expressions
  Exp_opt ::= empty | E | %eo:ID

Formal parameters
  Parameters ::= empty | ... | %va:ID | %f:ID | T | T , Parameters

List of attributes
  Attrs ::= empty | %A:ID | Attrib Attrs

Attributes
  Attrib ::= const | restrict | volatile | __attribute__ ( ( GAttr ) )

GCC Attributes
  GAttr ::= ident | ident ( AttrArg_List )

Lists of GCC Attribute arguments:
  AttrArg_List ::= AttrArg | %P:ID | AttrArg , AttrArg_List

GCC Attribute arguments  
  AttrArg ::= %p:ID | ident | ident ( AttrArg_List )

Instructions
  Instr ::= %i:ID ; | L = E ; | L Binop= E | Callres L ( Args )

Actual arguments
   Args ::= empty | %E:ID | E | E , Args

Call destination
   Callres ::= empty | L = | %lo:ID

Statements
  Stmt ::= %s:ID | if ( E ) then Stmt ; | if ( E ) then Stmt else Stmt ;
       | return Exp_opt | break ; | continue ; | { Stmt_list } 
       | while (E ) Stmt | Instr_list 

Lists of statements
   Stmt_list ::= empty | %S:ID | Stmt Stmt_list  
                | Type_spec Attrs Decl ; Stmt_list
                | Type_spec Attrs Decl = E ; Stmt_list
                | Type_spec Attrs Decl = L (Args) ; Stmt_list

List of instructions
   Instr_list ::= Instr | %I:ID | Instr Instr_list
\end{verbatim}

Notes regarding the syntax:
\begin{itemize}
\item In the grammar description above non-terminals are written with
uppercase initial

\item All of the patterns consist of the \t{\%} character followed by one or
two letters, followed by ``:'' and an indentifier. For each such
pattern there is a corresponding constructor of the \ciltyperef{formatArg}
type, whose name is the letter 'F' followed by the same one or two letters as
in the pattern. That constructor is used by the user code to pass a
\ciltyperef{formatArg} actual argument to the interpreted constructor and by
the interpreted deconstructor to return what was matched for a pattern.

\item If the pattern name is uppercase, it designates a list of the elements
designated by the corresponding lowercase pattern. E.g. \%E designated lists
of expressions (as in the actual arguments of a call).

\item The two-letter patterns whose second letter is ``o'' designate an
optional element. E.g. \%eo designates an optional expression (as in the
length of an array). 

\item Unlike in calls to \t{printf}, the pattern \%g is used for strings. 

\item The usual precedence and associativity rules as in C apply 

\item The pattern string can contain newlines and comments, using both the
\t{/* ... */} style as well as the \t{//} one. 

\item When matching a ``cast'' pattern of the form \t{( T ) E}, the
deconstructor will match even expressions that do not have the actual cast but
in that case the type is matched against the type of the expression. E.g. the
patters \t{"(int)\%e"} will match any expression of type \t{int} whether it
has an explicit cast or not. 

\item The \%k pattern is used to construct and deconstruct an integer type of
any kind. 

\item Notice that the syntax of types and declaration are the same (in order
to simplify the parser). This means that technically you can write a whole
declaration instead of a type in the cast. In this case the name that you
declare is ignored.

\item In lists of formal parameters and lists of attributes, an empty list in
the pattern matches any formal parameters or attributes. 

\item When matching types, uses of named types are unrolled to expose a real
type before matching. 

\item The order of the attributes is ignored during matching. The the pattern
for a list of attributes contains \%A then the resulting \t{formatArg} will be
bound to {\bf all} attributes in the list. For example, the pattern \t{"const
\%A"} matches any list of attributes that contains \t{const} and binds the
corresponding placeholder to the entire list of attributes, including
\t{const}. 
 
\item All instruction-patterns must be terminated by semicolon

\item The autoincrement and autodecrement instructions are not supported. Also
not supported are complex expressions, the \t{&&} and \t{||} shortcut
operators, and a number of other more complex instructions or statements. In
general, the patterns support only constructs that can be represented directly
in CIL.

\item The pattern argument identifiers are not used during deconstruction.
Instead, the result contains a sequence of values in the same order as the
appearance of pattern arguments in the pattern.

\item You can mix statements with declarations. For each declaration a new
  temporary will be constructed (using a function you provive). You can then
  refer to that temporary by name in the rest of the pattern.

\item The \t{\%v:} pattern specifier is optional.
\end{itemize}

 The following function are defined in the \t{Formatcil} module for
constructing and deconstructing:
\begin{itemize}
\item \formatcilvalref{cExp} constructs \ciltyperef{exp}.
\item \formatcilvalref{cType} constructs \ciltyperef{typ}.
\item \formatcilvalref{cLval} constructs \ciltyperef{lval}.
\item \formatcilvalref{cInstr} constructs \ciltyperef{instr}.
\item \formatcilvalref{cStmt} and \formatcilvalref{cStmts} construct \ciltyperef{stmt}.
\item \formatcilvalref{dExp} deconstructs \ciltyperef{exp}.
\item \formatcilvalref{dType} deconstructs \ciltyperef{typ}.
\item \formatcilvalref{dLval} deconstructs \ciltyperef{lval}.
\item \formatcilvalref{dInstr} deconstructs \ciltyperef{lval}.
\end{itemize}

 Below is an example using interpreted constructors. This example generates
the CIL representation of code that scans an array backwards and initializes
every even-index element with an expression:
\begin{code}
Formatcil.cStmts
  "int idx = sizeof(array) / sizeof(array[0]) - 1;
   while(idx >= 0) {
     // Some statements to be run for all the elements of the array
     %S:init
     if(! (idx & 1)) 
       array[idx] = %e:init_even;
     /* Do not forget to decrement the index variable */
     idx = idx - 1;
   }"
  (fun n t -> makeTempVar myfunc ~name:n t)
  [ ("array", Fv myarray); 
    ("init", FS [stmt1; stmt2; stmt3]);
    ("init_even", Fe init_expr_for_even_elements) ]
\end{verbatim}\end{code}

 To write the same CIL statement directly in CIL would take much more effort.
Note that the pattern is parsed only once and the result (a function that
takes the arguments and constructs the statement) is memoized. 

  \subsubsection{Performance considerations for interpreted constructors}
 
 Parsing the patterns is done with a LALR parser and it takes some time. To
improve performance the constructors and deconstructors memoize the parsed
patterns and will only compile a pattern once. Also all construction and
deconstruction functions can be applied partially to the pattern string to
produce a function that can be later used directly to construct or
deconstruct. This function appears to be about two times slower than if the
construction is done using the CIL constructors (without memoization the
process would be one order of magnitude slower.) However, the convenience of
interpreted constructor might make them a viable choice in many situations
when performance is not paramount (e.g. prototyping).


 \subsection{Printing and Debugging support}
 
The Modules \moduleref{Pretty} and \moduleref{Errormsg} contain respectively
utilities for pretty printing and reporting errors and provide a convenient
\t{printf}-like interface. 

 Additionally, CIL defines for each major type a pretty-printing function that
you can use in conjunction with the \moduleref{Pretty} interface. The
following are some of the pretty-printing functions:
\begin{itemize}
\item \cilvalref{d\_exp} - print an expression
\item \cilvalref{d\_type} - print a type
\item \cilvalref{d\_lval} - print an lvalue
\item \cilvalref{d\_global} - print a global
\item \cilvalref{d\_stmt} - print a statment
\item \cilvalref{d\_instr} - print an instruction
\item \cilvalref{d\_init} - print an initializer
\item \cilvalref{d\_attr} - print an attribute
\item \cilvalref{d\_attrlist} - print a set of attributes
\item \cilvalref{d\_loc} - print a location
\item \cilvalref{d\_ikind} - print an integer kind
\item \cilvalref{d\_fkind} - print a floating point kind
\item \cilvalref{d\_const} - print a constant
\item \cilvalref{d\_storage} - print a storage specifier
\end{itemize}

 You can even customize the pretty-printer by creating instances of
\cilprinter{}. Typically such an instance extends
\cilvalref{defaultCilPrinter}. Once you have a customized pretty-printer you
can use the following printing functions:
\begin{itemize}
\item \cilvalref{printExp} - print an expression
\item \cilvalref{printType} - print a type
\item \cilvalref{printLval} - print an lvalue
\item \cilvalref{printGlobal} - print a global
\item \cilvalref{printStmt} - print a statment
\item \cilvalref{printInstr} - print an instruction
\item \cilvalref{printInit} - print an initializer
\item \cilvalref{printAttr} - print an attribute
\item \cilvalref{printAttrs} - print a set of attributes
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
\subsection{Attributes}\label{sec-attrib}\cutname{attributes.html}

 In CIL you can attach attributes to types and to names (variables, functions
and fields). Attributes are represented using the type \ciltyperef{attribute}.
An attribute consists of a name and a number of arguments (represented using
the type \ciltyperef{attrparam}). Almost any expression can be used as an
attribute argument. Attributes are stored in lists sorted by the name of the
attribute. To maintain list ordering, use the functions
\cilvalref{typeAttrs} to retrieve the attributes of a type and the functions
\cilvalref{addAttribute} and \cilvalref{addAttributes} to add attributes.
Alternatively you can use \cilvalref{typeAddAttributes} to add an attribute to
a type (and return the new type).

 GCC already has extensive support for attributes, and CIL extends this
support to user-defined attributes. A GCC attribute has the syntax:
 
\begin{verbatim}
 gccattribute ::= __attribute__((attribute))    (Note the double parentheses)
\end{verbatim}

 Since GCC and MSVC both support various flavors of each attribute (with or
without leading or trailing \_) we first strip ALL leading and trailing \_
from the attribute name (but not the identified in [ACons] parameters in
\ciltyperef{attrparam}). When we print attributes, for GCC we add two leading
and two trailing \_; for MSVC we add just two leading \_.
 
 There is support in CIL so that you can control the printing of attributes
(see \cilvalref{setCustomPrintAttribute} and
\cilvalref{setCustomPrintAttributeScope}). This custom-printing support is now
used to print the "const" qualifier as "\t{const}" and not as
"\t{\_\_attribute\_\_((const))}".


 The attributes are specified in declarations. This is unfortunate since the C
syntax for declarations is already quite complicated and after writing the
parser and elaborator for declarations I am convinced that few C programmers
understand it completely. Anyway, this seems to be the easiest way to support
attributes. 

 Name attributes must be specified at the very end of the declaration, just
before the \t{=} for the initializer or before the \t{,} the separates a
declaration in a group of declarations or just before the \t{;} that
terminates the declaration. A name attribute for a function being defined can
be specified just before the brace that starts the function body.

 For example (in the following examples \t{A1},...,\t{An} are type attributes
and \t{N} is a name attribute (each of these uses the \t{\_\_attribute\_\_} syntax):

\begin{code}
 int x N;
 int x N, * y N = 0, z[] N;
 extern void exit() N;
 int fact(int x) N { ... }
\end{verbatim}\end{code}


 Type attributes can be specified along with the type using the following
 rules: 
\begin{enumerate}
 \item The type attributes for a base type (int, float, named type, reference
    to struct or union or enum) must be specified immediately following the
    type (actually it is Ok to mix attributes with the specification of the
    type, in between unsigned and int for example).

  For example:
\begin{code}
  int A1 x N;  /* A1 applies to the type int. An example is an attribute
                   "even" restricting the type int to even values. */
  struct foo A1 A2 x; // Both A1 and A2 apply to the struct foo type
\end{verbatim}\end{code}
 
 \item The type attributes for a pointer type must be specified immediately
 after the * symbol.
\begin{code}
 /* A pointer (A1) to an int (A2) */
 int A2 * A1 x;
 /* A pointer (A1) to a pointer (A2) to a float (A3) */
 float A3 * A2 * A1 x;
\end{verbatim}\end{code}


 Note: The attributes for base types and for pointer types are a strict
 extension of the ANSI C type qualifiers (const, volatile and restrict). In
 fact CIL treats these qualifiers as attributes. 

  \item The attributes for a function type or for an array type can be
     specified using parenthesized declarators.

   For example:
\begin{code}
   /* A function (A1) from int (A2) to float (A3) */
   float A3 (A1 f)(int A2);

   /* An array (A1) of int (A2) */
   int A2 (A1 x0)[]

   /* Array (A1) of pointers (A2) to functions (A3) that take an int (A4) and 
    * return a pointer (A5) to int (A6)  */
   int A6 * A5 (A3 * A2 (A1 x1)[5])(int A4);


   /* A function (A4) that takes a float (A5) and returns a pointer (A6) to an 
    * int (A7) */
   extern int A7 * A6 (A4 x2)(float A5 x);

   /* A function (A1) that takes a int (A2) and that returns a pointer (A3) to 
    * a function (A4) that takes a float (A5) and returns a pointer (A6) to an 
    * int (A7) */
   int A7 * A6 (A4 * A3 (A1 x3)(int A2 x))(float A5) {
      return & x2;
   }
\end{verbatim}\end{code}

\end{enumerate}

 Note: ANSI C does not allow the specification of type qualifiers for function
and array types, although it allows for the parenthesized declarator. With
just a bit of thought (looking at the first few examples above) I hope that
the placement of attributes for function and array types will seem intuitive.

 This extension is not without problems however. If you want to refer just to
a type (in a cast for example) then you leave the name out. But this leads to
strange conflicts due to the parentheses that we introduce to scope the
attributes. Take for example the type of x0 from above. It should be written
as: 
 
\begin{code}
        int A2 (A1 )[]
\end{verbatim}\end{code}

 But this will lead most C parsers into deep confusion because the parentheses
around A1 will be confused for parentheses of a function designator. To push
this problem around (I don't know a solution) whenever we are about to print a
parenthesized declarator with no name but with attributes, we comment out the
attributes so you can see them (for whatever is worth) without confusing the
compiler. For example, here is how we would print the above type:

\begin{code}
        int A2 /*(A1 )*/[]
\end{verbatim}\end{code}

 \paragraph{Handling of predefined GCC attributes}

 GCC already supports attributes in a lot of places in declarations. The only
place where we support attributes and GCC does not is right before the \{ that
starts a function body. 

 GCC classifies its attributes in attributes for functions, for variables and
for types, although the latter category is only usable in definition of struct
or union types and is not nearly as powerful as the CIL type attributes. We
have made an effort to reclassify GCC attributes as name and type attributes
(they only apply for function types). Here is what we came up with:

\begin{itemize}
  \item GCC name attributes:
   
   section, constructor, destructor, unused, weak, no\_instrument\_function,
   noreturn, alias, no\_check\_memory\_usage, dllinport, dllexport, exception,
   model

      Note: the "noreturn" attribute would be more appropriately qualified as a
      function type attribute. But we classify it as a name attribute to make
      it easier to support a similarly named MSVC attribute. 
  
  \item GCC function type attributes:

    fconst (printed as "const"), format, regparm, stdcall,
    cdecl, longcall

  I was not able to completely decipher the position in which these attributes
  must go. So, the CIL elaborator knows these names and applies the following
  rules: 
  \begin{itemize}
  \item All of the name attributes that appear in the specifier part (i.e. at
  the beginning) of a declaration are associated with all declared names. 

  \item All of the name attributes that appear at the end of a declarator are
  associated with the particular name being declared.

  \item More complicated is the handling of the function type attributes, since
     there can be more than one function in a single declaration (a function
     returning a pointer to a function). Lacking any real understanding of how
     GCC handles this, I attach the function type attribute to the "nearest"
     function. This means that if a pointer to a function is "nearby" the
     attribute will be correctly associated with the function. In truth I pray
     that nobody uses declarations as that of x3 above. 
  \end{itemize}
\end{itemize}

\paragraph{Handling of predefined MSVC attributes}

  MSVC has two kinds of attributes, declaration modifiers to be printed before
  the storage specifier using the notation "\t{\_\_declspec(...)}" and a few
  function type attributes, printed almost as our CIL function type
  attributes. 

   The following are the name attributes that are printed using
   \t{\_\_declspec} right before the storage designator of the declaration:
   thread, naked, dllimport, dllexport, noreturn


   The following are the function type attributes supported by MSVC: 
   fastcall, cdecl, stdcall

   It is not worth going into the obscure details of where MSVC accepts these
   type attributes. The parser thinks it knows these details and it pulls
   these attributes from wherever they might be placed. The important thing
   is that MSVC will accept if we print them according to the rules of the CIL
   attributes ! 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The CIL Driver}\label{sec-driver}\cutname{cilly.html}

 We have packaged CIL as an application \t{cilly} that contains certain
example modules, such as \t{logwrites.ml} (a module
that instruments code to print the addresses of memory locations being
written). Normally, you write another module like that, add command-line
options and an invocation of your module in \t{src/main.ml}. Once you compile
CIL you will obtain the file \t{obj/cilly.asm.exe}. 

 We wrote a driver for this executable that makes it easy to invoke your
analysis on existing C code with very little manual intervention. This driver
is \t{bin/cilly} and is quite powerful. Note that the \t{cilly} script
is configured during installation with the path where CIL resides. This means
that you can move it to any place you want. 

 A simple use of the driver is:
\begin{verbatim}
bin/cilly -D HAPPY_MOOD -I myincludes hello.c -o hello
\end{verbatim}

 This performs the following actions: 
\begin{itemize}
\item preprocessing using the -D and -I arguments with the resulting file left in \t{hello.i}, 
\item the invocation of the \t{cilly.asm} application which parses \t{hello.i}
converts it to CIL and the pretty-prints it to \t{hellocil.c}
\item another round of preprocessing with the result placed in \t{hellocil.i}
\item the true compilation with the result in \t{hellocil.o}
\item a linking phase with the result in \t{hello}
\end{itemize}
 
 Note that \t{cilly} behaves like the \t{gcc} compiler with the additional
effect that CIL sees all the source code. This makes it easy
to use it with existing \t{Makefiles}:
\begin{verbatim}
make CC="bin/cilly" LD="bin/cilly"
\end{verbatim}

 \t{cilly} can also behave as the Microsoft Visual C compiler, if the first
 argument is \t{--mode=MSVC}:
\begin{verbatim}
bin/cilly --mode=MSVC /D HAPPY_MOOD /I myincludes hello.c /Fe hello.exe
\end{verbatim}

 (This in turn will pass a \t{--MSVC} flag to the underlying \t{cilly.asm}
 process which will make it understand the Microsoft Visual C extensions)

 \t{cilly} can also behave as the archiver \t{ar}, if it is passed an
argument \t{--mode=AR}. Note that only the \t{cr} mode is supported (create a
new archive and replace all files in there). Note that the previous version of
the archive is lost. 

 Furthermore, \t{cilly} allows you to pass some arguments on to the
underlying \t{cilly.asm} process. As a general rule all arguments that start
with \t{--} and that \t{cilly} itself does not process, are passed on. For
example, 
\begin{verbatim}
bin/cilly --logwrites -D HAPPY_MOOD -I myincludes hello.c -o hello.exe
\end{verbatim}

 will produce a file \t{hellocil.c} that prints all the memory addresses
written by the application. 

 The most powerful feature of \t{cilly} is that it can collect all the
sources in your project, merge them into one file and then apply CIL. This
makes it a breeze to do whole-program analysis and transformation. All you
have to do is to pass the \t{--merge} flag to \t{cilly}:
\begin{verbatim}
make CC="bin/cilly --logwrites --merge"
\end{verbatim}

 You can even leave some files untouched:
\begin{verbatim}
make CC="bin/cilly --logwrites --merge --leavealone=foo --leavealone=bar"
\end{verbatim}

 This will merge all the files except those with the basename \t{foo} and
\t{bar}. Those files will be compiled as usual and then linked in at the very
end. 

 The sequence of actions performed by \t{cilly} depends on whether merging
is turned on or not:
\begin{itemize}
\item If merging is off
  \begin{enumerate}
    \item For every file \t{file.c} to compile
         \begin{enumerate}
            \item Preprocess the file with the given arguments to 
                  produce \t{file.i}
            \item Invoke \t{cilly.asm} to produce a \t{filecil.c}
            \item Preprocess to \t{filecil.i}
            \item Invoke the underlying compiler to produce \t{filecil.o}
         \end{enumerate}
    \item Link the resulting objects
  \end{enumerate}
\item If merging is on
  \begin{enumerate}
    \item For every file \t{file.c} to compile
         \begin{enumerate}
            \item Preprocess the file with the given arguments to 
                  produce \t{file.i}
            \item Save the preprocessed source as \t{file.o}
         \end{enumerate}
    \item When linking executable \t{hello.exe}, look at every object 
          file that must be linked and see if it actually 
          contains preprocessed source. Pass all those files to a 
          special merging application (described in
          \secref{merger}) to produce \t{hello.exe\_comb.c}
    \item Invoke \t{cilly.asm} to produce a \t{hello.exe\_combcil.c}
    \item Preprocess to \t{hello.exe\_combcil.i}
    \item Invoke the underlying compiler to produce \t{hello.exe\_combcil.o}
    \item Invoke the actual linker to produce \t{hello.exe}
  \end{enumerate}
\end{itemize}

 Note that files that you specify with \t{--leavealone} are not merged and
never presented to CIL. They are compiled as usual and then are linked in at
the end. 

 And a final feature of \t{cilly} is that it can substitute copies of the
system's include files:

\begin{verbatim}
make CC="bin/cilly --includedir=myinclude"
\end{verbatim}

 This will force the preprocessor to use the file \t{myinclude/xxx/stdio.h}
(if it exists) whenever it encounters \t{#include <stdio.h>}. The \t{xxx} is
a string that identifies the compiler version you are using. This modified
include files should be produced with the patcher script (see
\secref{patcher}).

  \subsection{\t{cilly} Options}

 Among the options for the \t{cilly} you can put anything that can normally
go in the command line of the compiler that \t{cilly} is impersonating.
\t{cilly} will do its best to pass those options along to the appropriate
subprocess. In addition, the following options are supported (a complete and
up-to-date list can always be obtained by running \t{cilly --help}):

\begin{itemize}
\item \t{--mode=mode} This must be the first argument if present. It makes
\t{cilly} behave as a given compiled. The following modes are recognized: 
     \begin{itemize}
        \item GNUCC - the GNU C Compiler. This is the default.
        \item MSVC - the Microsoft Visual C compiler. Of course, you should
                     pass only MSVC valid options in this case. 
        \item AR - the archiver \t{ar}. Only the mode \t{cr} is supported and
                   the original version of the archive is lost. 
     \end{itemize}
\item \t{--help} Prints a list of the options supported.
\item \t{--verbose} Prints lots of messages about what is going on.
\item \t{--stages} Less than \t{--verbose} but lets you see what \t{cilly}
                   is doing. 
\item \t{--merge} This tells \t{cilly} to first attempt to collect into one
source file all of the sources that make your application, and then to apply
\t{cilly.asm} on the resulting source. The sequence of actions in this case is
described above and the merger itself is described in \secref{merger}.

\item \t{--leavealone=xxx}. Do not merge and do not present to CIL the files
whose basename is "xxx". These files are compiled as usual and linked in at
the end. 
\item \t{--includedir=xxx}. Override the include files with those in the given
directory. The given directory is the same name that was given an an argument
to the patcher (see \secref{patcher}). In particular this means that
that directory contains subdirectories named based on the current compiler
version. The patcher creates those directories. 
\item \t{--usecabs}. Do not CIL, but instead just parse the source and print
its AST out. This should looked like the preprocessed file. This is useful
when you suspect that the conversion to CIL phase changes the meaning of the
program. 
\end{itemize}
 
 
  \subsection{\t{cilly.asm} Options}

 All of the options that start with \t{--} and are not understood by
\t{cilly} are passed on to \t{cilly.asm}. The following options are
supported:
\begin{itemize}
\item \t{--out <xxx>}. The name of the pretty-printed file.
\item \t{--verbose}. Print lots of random stuff. This is passed on from
\t{cilly}.
\item \t{-help}. Print the help. Actually \t{cilly} will do this if you
      pass it \t{--help}.  
\item \t{--check}. Run a consistency check over the CIL after every operation. 
\item \t{--MSVC}. Enable the MSVC extensions and pretty-print for consumption
by MSVC.
\item \t{--logcalls}. Insert code in the processed source to print the name of
functions as are called. Implemented in \t{src/logcalls.ml}.
\item \t{--logwrites}. Insert code in the processed source to print the
address of all memory writes. Implemented in \t{src/logwrites.ml}.
\item \t{--heapify}. Apply the heapify transformation.
                     Implemented in \t{src/heapify.ml}.
\item \t{--heapify}. Apply the StackGuard transformation.
                     Implemented in \t{src/stackguard.ml}.
\item \t{--warnall}. Print all the warnings.
\item \t{--log=xxx}. Set \t{xxx} to be the name of the log file for the CIL
application. By default \t{stderr} is used.
\item \t{--keepunused}. Do not attempt to remove the unused variables and
       types from CIL. 
\item \t{--noPrintLn}. Do not print line numbers.
\item \t{--commPrintLn}. Print line numbers but in comments.
\item \t{--printCilAsIs}. Do not attempt to simplify the program while
  printing. If this is turned on, then all loops will be printed as
  ``while(1)'', as they are in the internal language.
\item \t{--extrafiles <xxx>}. Give the name of a text file that contains
whitespace-separated named of additional files to process.
\end{itemize}


\section{Controlling CIL}

 In the process of converting a C file to CIL we drop the unused prototypes
and even inline function definitions. This results in much smaller files. If
you do not want this behavior then you must pass the \t{--keepunused} argument
to the CIL application. 

 Alternatively you can put the following pragma in the code (instructing CIL
to specifically keep the declarations and definitions of the function
\t{func1} and variable \t{var2}, the definition of type \t{foo} and of
structure \t{bar}):
\begin{code}
#pragma cilnoremove("func1", "var2", "type foo", "struct bar")
\end{verbatim}\end{code}



\section{GCC Extensions}

 The CIL parser handles most of the \t{gcc}
\ahref{http://gcc.gnu.org/onlinedocs/gcc-3.0.2/gcc\_5.html#SEC67}{extensions}
and compiles them to CIL. The following extensions are not handled (note that
we are able to compile a large number of programs, including the Linux kernel,
without encountering these):

\begin{enumerate}
\item Nested function definitions.
\item Constructing function calls.
\item Naming an expression's type.
\item Complex numbers
\item Hex floats
\item Subscripts on non-lvalue arrays.
\item Forward function parameter declarations
\end{enumerate}

 The following extensions are handled, typically by compiling them away:
\begin{enumerate}
\item Attributes for functions, variables and types. In fact, we have a clear
specification (see \secref{attrib}) of how attributes are interpreted. The
specification extends that of \t{gcc}.
\item Old-style function definitions and prototypes. These are translated to
new-style. 
\item Locally-declared labels. As part of the translation to CIL, we generate
new labels as needed. 
\item Labels as values and computed goto. This allows a program to take the
address of a label and to manipulate it as any value and also to perform a
computed goto. We compile this by assigning each label whose address is taken
a small integer that acts as its address. Every computed \t{goto} in the body
of the function is replaced with a \t{switch} statement. If you want to invoke
the label from another function, you are on your own (the \t{gcc}
documentation says the same.)
\item Generalized lvalues. You can write code like \t{(a, b) += 5} and it gets
translated to CIL. 
\item Conditionals with omitted operands. Things like \t{x ? : y} are
translated to CIL.
\item Double word integers. The type \t{long long} and the \t{LL} suffix on
constants is understood. This is currently interpreted as 64-bit integers.
\item Local arrays of variable length. These are converted to uses of
\t{alloca}, the array variable is replaced with a pointer to the allocated
array and the instances of \t{sizeof(a)} are adjusted to return the size of
the array and not the size of the pointer. 
\item Non-constant local initializers. Like all local initializers these are
compiled into assignments. 
\item Compound literals. These are also turned into assignments.
\item Designated initializers. The CIL parser actually supports the full ISO
syntax for initializers, which is more than both \t{gcc} and \t{MSVC}. I
(George) think that this is the most complicated part of the C language and
whoever designed it should be banned from ever designing languages again.
\item Case ranges. These are compiled into separate cases. There is no code
duplication, just a larger number of \t{case} statements.
\item Transparent unions. This is a strange feature that allows you to define
a function whose formal argument has a (tranparent) union type, but the
argument is called as if it were the first element of the union. This is
compiled away by saying that the type of the formal argument is that of the
first field, and the first thing in the function body we copy the formal into
a union. 

\item Inline assembly-language. The full syntax is supported and it is carried
as such in CIL.

\item Function names as strings. The identifiers \t{\_\_FUNCTION\_\_} and
\t{\_\_PRETTY\_FUNCTION\_\_} are replaced with string literals. 

\item Keywords \t{typeof}, \t{alignof}, \t{inline} are supported. 
\end{enumerate}

\section{CIL Limitations}

 There are several implementation details of CIL that might make it unusable
 or less than ideal for certain tasks:

\begin{itemize}
\item CIL operates after preprocessing. If you need to see comments, for
example, you cannot use CIL. But you can use attributes and pragmas instead.
And there is some support to help you patch the include files before they are
seen by the preprocessor. This is how we turn some #define that we don't like
into function calls for example. 

\item CIL does transform the code in a non-trivial way. This is done in order
to make most analyses easier. But if you want to see the code \t{e1, e2++}
exactly as it appears in the code, then you should not use CIL. 

\item CIL removes all local scopes and moves all variables to function
scope. It also separates a declaration with an initializer into a declaration
plus an assignment. The unfortunate effect of this transformation is that
local variables cannot have the \t{const} qualifier.

\end{itemize}
 
\section{Known Bugs and Limitations}

\begin{itemize}

\item In the new versions of \t{glibc} there is a function
  \t{\_\_builtin\_va\_arg} that takes a type as its second argument. CIL
  handles that through a slight trick. As it parses the function it changes a
  call like:
\begin{verbatim}
  mytype x = __builtin_va_arg(marker, mytype)
\end{verbatim}
 into 
\begin{verbatim}
 mytype x;
 __builtin_va_arg(marker, sizeof(mytype), &x);
\end{verbatim}

 The latter form is used internally in CIL. However, the CIL pretty printer
 will try to emit the original code. 


\item The implementation of \t{bitsSizeOf} does not take into account the
packing pragmas. However it was tested to be accurate on cygwin/gcc-2.95.3,
Linux/gcc-2.95.3 and on Windows/MSVC.

\item We do not support tri-graph sequences (ISO 5.2.1.1).

\item GCC has a strange feature called ``extern inline''. Such a function can
be defined twice: first with the ``extern inline'' specifier and the second
time without it. If optimizations are turned off then the ``extern inline''
definition is considered a prototype (its body is ignored). If optimizations
are turned on then the extern inline function is inlined at all of its
occurrences from the point of its definition all the way to the point where the
(optional) second definition appears. No body is generated for an extern
inline function. A body is generated for the real definition and that one is
used in the rest of the file. 

 CIL will rename your extern inline function (and its uses) with the suffix
 \t{\_\_extinline}. This means that if you have two such definition, that do
 different things and the optimizations are not on, then the CIL version might
 compute a different answer !

 Also, if you have multiple extern inline declarations then CIL will ignore
but the first one. This is not so bad because GCC itself would not like it. 

\item There are still a number of bugs in handling some obscure features of
GCC. For example, when you use variable-length arrays, CIL turns them into
calls to \t{alloca}. This means that they are deallocated when the function
returns and not when the local scope ends. 

\item CIL cannot parse a line containing an empty #pragma.

\item CIL cannot parse the following code (fixing this problem would require
extensive hacking of the LALR grammar):
\begin{code}
int bar(int ()); // This prototype cannot be parsed
int bar(int x()); // If you add a name to the function, it works
int bar(int (*)()); // This also works (and it is more appropriate)
\end{verbatim}\end{code}

\item CIL also cannot parse certain K&R old-style prototypes with missing
return type:
\begin{code}
g(); // This cannot be parsed
int g(); // This is Ok
\end{verbatim}\end{code}

\item CIL does not understand some obscure combinations of type specifiers
(``signed'' and ``unsigned'' applied to typedefs that themselves contain a
sign specification; you could argue that this should not be allowed anyway):
\begin{code}
typedef signed char __s8;
__s8 unsigned uchartest; // This is unsigned char for gcc
\end{verbatim}\end{code}
\end{itemize}

  \section{Using the merger}\label{sec-merger}\cutname{merger.html}

 There are many program analyses that are more effective when
done on the whole program.

 The merger is a tool that combines all of the C source files in a project
into a single C file. There are two tasks that a merger must perform:
\begin{enumerate}
\item Detect what are all the sources that make a project and with what
compiler arguments they are compiled.

\item Merge all of the source files into a single file. 
\end{enumerate}

 For the first task the merger impersonates a compiler and a linker (both a
GCC and a Microsoft Visual C mode are supported) and it expects to be invoked
(from a build script or a Makefile) on all sources of the project. When
invoked to compile a source the merger just preprocesses the source and saves
the result using the name of the requested object file. By preprocessing at
this time the merger is able to take into account variations in the command
line arguments that affect preprocessing of different source files.

 When the merger is invoked to link a number of object files it collects the
preprocessed sources that were stored with the names of the object files, and
invokes the merger proper. Note that arguments that affect the compilation or
linking must be the same for all source files.

 For the second task, the merger essentially concatenates the preprocessed
sources with care to rename conflicting file-local declarations (we call this
process alpha-conversion of a file). The merger also attempts to remove
duplicate global declarations and definitions. Specifically the following
actions are taken: 

\begin{itemize}
\item File-scope names (\t{static} globals, names of types defined with
\t{typedef}, and structure/union/enumeration tags) are given new names if they
conflict with declarations from previously processed sources. The new name is
formed by appending the suffix \t{\_\_\_n}, where \t{n} is a unique integer
identifier. Then the new names are applied to their occurrences in the file. 

\item Non-static declarations and definitions of globals are never renamed.
But we try to remove duplicate ones. Equality of globals is detected by
comparing the printed form of the global (ignoring the line number directives)
after the body has been alpha-converted. This process is intended to remove
those declarations (e.g. function prototypes) that originate from the same
include file. Similarly, we try to eliminate duplicate definitions of
\t{inline} functions, since these occasionally appear in include files.

\item The types of all global declarations with the same name from all files
are compared for type isomorphism. During this process, the merger detects all
those isomorphisms between structures and type definitions that are {\bf
required} for the merged program to be legal. Such structure tags and
typenames are coalesced and given the same name. 

\item Besides the structure tags and type names that are required to be
isomorphic, the merger also tries to coalesce definitions of structures and
types with the same name from different file. However, in this case the merger
will not give an error if such definitions are not isomorphic; it will just
use different names for them. 

\item In rare situations, it can happen that a file-local global in
encountered first and it is not renamed, only to discover later when
processing another file that there is an external symbol with the same name.
In this case, a second pass is made over the merged file to rename the
file-local symbol. 
\end{itemize}

 Here is an example of using the merger:

 The contents of \t{file1.c} is:
\begin{code}
struct foo; // Forward declaration
extern struct foo *global;
\end{verbatim}\end{code}

 The contents of \t{file2.c} is:

\begin{code}
struct bar {
 int x;
 struct bar *next;
};
extern struct bar *global;
struct foo {
 int y;
};
extern struct foo another;
\end{verbatim}\end{code}

 And the result of merging file1.c and file2.c is:

\begin{code}
// from file1.c
struct foo; // Forward declaration
extern struct foo *global;

// from file2.c
struct foo {
 int x;
 struct foo *next;
};
struct foo___1 {
 int y;
};
extern struct foo___1 another;
\end{verbatim}\end{code}

    \section{Using the patcher}\label{sec-patcher}\cutname{patcher.html}

 Occasionally we have needed to modify slightly the standard include files.
So, we developed a simple mechanism that allows us to create modified copies
of the include files and use them instead of the standard ones. For this
purpose we specify a patch file and we run a program caller Patcher which
makes modified copies of include files and applies the patch.

 The patcher is invoked as follows: 
\begin{verbatim}
bin/patcher [options]

Options:
  --help       Prints this help message
  --verbose    Prints a lot of information about what is being done
  --mode=xxx   What tool to emulate: 
                GNUCC     - GNU CC
                MSVC      - MS VC cl compiler

  --dest=xxx   The destination directory. Will make one if it does not exist
  --patch=xxx  Patch file (can be specified multiple times)
  --ppargs=xxx An argument to be passed to the preprocessor (can be specified
               multiple times)

  --ufile=xxx  A user-include file to be patched (treated as \#include "xxx")
  --sfile=xxx  A system-include file to be patched (treated as \#include <xxx>)
 
  --clean       Remove all files in the destination directory
  --dumpversion Print the version name used for the current compiler

 All of the other arguments are passed to the preprocessor.
\end{verbatim}

 Based on the given \t{mode} and the current version of the compiler (which
the patcher can print when given the \t{dumpversion} argument) the patcher
will create a subdirectory of the \t{dest} directory (say \t{/usr/home/necula/cil/include}), such as:
\begin{verbatim}
/usr/home/necula/cil/include/gcc_2.95.3-5
\end{verbatim}

 In that file the patcher will copy the modified versions of the include files
specified with the \t{ufile} and \t{sfile} options. Each of these options can
be specified multiple times. 

 The patch file (specified with the \t{patch} option) has a format inspired by
the Unix \t{patch} tool. The file has the following grammar:

\begin{verbatim}
<<< flags
patterns
===
replacement
>>>
\end{verbatim}

 The flags are a comma separated, case-sensitive, sequence of keywords or
keyword = value. The following flags are supported:
\begin{itemize}
\item \t{file=foo.h} - will only apply the patch on files whose name is
                       \t{foo.h}. 
\item \t{optional} - this means that it is Ok if the current patch does not
match any of the processed files. 
\item \t{group=foo} - will add this patch to the named group. If this is not
specified then a unique group is created to contain just the current patch.
When all files specified in the command line have been patched, an error
message is generated for all groups for whom no member patch was used. We use
this mechanism to receive notice when the patch triggers are out-dated with
respect to the new include files. 
\item \t{system=sysname} - will only consider this pattern on a given
operating system. The ``sysname'' is reported by the ``\$\^O'' variable in
Perl, except that Windows is always considered to have sysname
``cygwin.'' For Linux use ``linux'' (capitalization matters).
\item \t{ateof} - In this case the patterns are ignored and the replacement
text is placed at the end of the patched file. Use the \t{file} flag if you
want to restrict the files in which this replacement is performed. 
\end{itemize}


 The patterns can consist of several groups of lines separated by the \t{|||}
marker. Each of these group of lines is a multi-line pattern that if found in
the file will be replaced with the text given at the end of the block. 

 The matching is space-insensitive.

 All of the markers \t{<<<}, \t{|||}, \t{===} and \t{>>>} must appear at the
beginning of a line but they can be followed by arbitrary text (which is
ignored).

 The replacement text can contain the special keyword \t{@\_\_pattern\_\_@},
which is substituted with the pattern that matched. 


\section{Debugging support}\label{sec-debugger}

 Most of the time we debug our code using the Errormsg module along with the
pretty printer. But if you want to use the Ocaml debugger here is an easy way
to do it. Say that you want to debug the invocation of cilly that arises out
of the following command:
\begin{verbatim}
cilly -c hello.c 
\end{verbatim}

 You must follow the installation \ahref{../ccured/setup.html}{instructions}
to install the Elist support files for ocaml and to extend your .emacs
appropriately. Then from within Emacs you do
\begin{verbatim}
ALT-X my-camldebug
\end{verbatim}

 This will ask you for the command to use for running the Ocaml debugger
(initially the default will be ``ocamldebug'' or the last command you
introduced). You use the following command:
\begin{verbatim}
cilly --ocamldebug -c hello.c 
\end{verbatim}

 This will run \t{cilly} as usual and invoke the Ocaml debugger when the cilly
engine starts. The advantage of this way of invoking the debugger is that the
directory search paths are set automatically and the right set or arguments is
passed to the debugger. 


\section{Who Says C is Simple?}\label{sec-simplec}

 When I (George) started to write CIL I thought it was going to take two weeks.
Exactly a year has passed since then and I am still fixing bugs in it. This
gross underestimate was due to the fact that I thought parsing and making
sense of C is simple. You probably think the same. What I did not expect was
how many dark corners this language has, especially if you want to parse
real-world programs such as those written for GCC or if you are more ambitious
and you want to parse the Linux or Windows NT sources (both of these were
written without any respect for the standard and with the expectation that
compilers will be changed to accommodate the program). 

 The following examples were actually encountered either in real programs or
are taken from the ISO C99 standard or from the GCC's testcases. My first
reaction when I saw these was: {\em Is this C?}. The second one was : {\em
What the hell does it mean?}. 

 If you are contemplating doing program analysis for C on abstract-syntax
trees then your analysis ought to be able to handle these things. Or, you can
use CIL and let CIL translate them into clean C code. 

%
% Note: the cilcode environment is bogus. You should preprocess this source
% with cilcode.pl !!!
%
%
 \subsection{Standard C}

\begin{enumerate}

\item Why does the following code return 0 for most values of \t{x}? (This
should be easy.)

\begin{cilcode}[local]
  int x;
  return x == (1 && x);
\end{cilcode}

\item Why does the following code return 0 and not -1? (Answer: because
\t{sizeof} is unsigned, thus the result of the subtraction is unsigned, thus
the shift is logical.)

\begin{cilcode}[local]
 return ((1 - sizeof(int)) >> 32);
\end{cilcode}

\item Scoping rules can be tricky. This function returns 5.

\begin{cilcode}[global]
int x = 5;
int f() {
  int x = 3;
  {
    extern int x;
    return x;
  }
}
\end{cilcode}

\item Functions and function pointers are implicitly converted to each other. 

\begin{cilcode}[global]
int (*pf)(void);
int f(void) {

   *pf = f; // This looks ok
   pf(); // Invoke a function pointer?     
   ****pf = f; // Looks strange but Ok
   ****pf = *********f; // Looks strange but Ok
   (***************f)(); // Also Ok             
}
\end{cilcode}

\item Initializer with designators are one of the hardest parts about ISO C.
Neither MSVC or GCC implement them fully. GCC comes close though. What is the
final value of \t{i.nested.y} and \t{i.nested.z}? (Answer: 2 and respectively
6). 

\begin{cilcode}[global]
struct { 
   int x; 
   struct { 
       int y, z; 
   } nested;
} i = { .nested.y = 5, 6, .x = 1, 2 };               
\end{cilcode}

\item This is from c-torture. This function returns 1.

\begin{cilcode}[global]
typedef struct
{
  char *key;
  char *value;
} T1;

typedef struct
{
  long type;
  char *value;
} T3;

T1 a[] =
{
  {
    "",
    ((char *)&((T3) {1, (char *) 1}))
  }
};
int main() {
   T3 *pt3 = (T3*)a[0].value;
   return pt3->value;
}
\end{cilcode}

\item Another one with constructed literals. This one is legal according to
the GCC documentation but somehow GCC chokes on (it works in CIL though). This
code returns 2.

\begin{cilcode}[local]
 return ((int []){1,2,3,4})[1];
\end{cilcode}

\end{enumerate}

 \subsection{GCC ugliness}\label{sec-ugly-gcc}

\begin{enumerate}

\item GCC has generalized lvalues. You can take the address of a lot of
strange things:

\begin{cilcode}[local]
  int x, y, z;
  return &(x ? y : z) - & (x++, x);
\end{cilcode}

\item GCC lets you omit the second component of a conditional expression.

\begin{cilcode}[local]
  extern int f();
  return f() ? : -1; // Returns the result of f unless it is 0
\end{cilcode}

\item Computed jumps can be tricky. CIL compiles them away in a fairly clean
way but you are on your own if you try to jump into another function this way.

\begin{cilcode}[global]
static void *jtab[2]; // A jump table
static int doit(int x){
 
  static int jtab_init = 0;
  if(!jtab_init) { // Initialize the jump table
    jtab[0] = &&lbl1;
    jtab[1] = &&lbl2;
    jtab_init = 1;
  }
  goto *jtab[x]; // Jump through the table
lbl1:
  return 0;
lbl2:
  return 1;
}
 
int main(void){
  if (doit(0) != 0) exit(1);
  if (doit(1) != 1) exit(1);
  exit(0);
}
\end{cilcode}


\item A cute little example that we made up. What is the returned value?
(Answer: 1); 
\begin{cilcode}[local]
 return ({goto L; 0;}) && ({L: 5;});
\end{cilcode}

\item \t{extern inline} is a strange feature of GNU C. Can you guess what the
following code computes?

\begin{cilcode}[global]
extern inline foo(void) { return 1; }
int firstuse(void) { return foo(); }

// A second, incompatible definition of foo
int foo(void) { return 2; }

int main() {
    return foo() + firstuse();
}
\end{cilcode}

 The answer depends on whether the optimizations are turned on. If they are
then the answer is 3 (the first definition is inlined at all occurrences until
the second definition). If the optimizations are off, then the first
definition is ignore (treated like a prototype) and the answer is 4. 

 CIL will misbehave on this example, if the optimizations are turned off (it
 always returns 3).

\item GCC allows you to cast an object of a type T into a union as long as the
union has a field of that type:
\begin{cilcode}[global]
union u { 
   int i; 
   struct s { 
      int i1, i2;
   } s;
};

union u x = (union u)6;

int main() {
  struct s y = {1, 2};
  union u  z = (union u)y;
}
\end{cilcode}

\item GCC allows you to use the \t{\_\_mode\_\_} attribute to specify the size
of the integer instead of the standard \t{char}, \t{short} and so on:
\begin{cilcode}[global]
int __attribute__ ((__mode__ (  __QI__ ))) i8;
int __attribute__ ((__mode__ (  __HI__ ))) i16;
int __attribute__ ((__mode__ (  __SI__ ))) i32;
int __attribute__ ((__mode__ (  __DI__ ))) i64;
\end{cilcode}

\end{enumerate}

 \subsection{Microsoft VC ugliness}

 This compiler has few extensions, so there is not much to say here.

\begin{enumerate}
\item Why does the following code return 0 and not -1? (Answer: because of a
bug in Microsoft Visual C. It thinks that the shift is unsigned just because
the second operator is unsigned. CIL reproduces this bug when in MSVC mode.)

\begin{code}
 return -3 >> (8 * sizeof(int));
\end{verbatim}\end{code}

\item Unnamed fields in a structure seem really strange at first. It seems
that Microsoft Visual C introduced this extension, then GCC picked it up (but
in the process implemented it wrongly: in GCC the field \t{y} overlaps with
\t{x}!).

\begin{cilcode}[local]
struct {
  int x;
  struct {
     int y, z;
     struct {
       int u, v;
     };
 };
} a;
return a.x + a.y + a.z + a.u + a.v;
\end{cilcode}


\end{enumerate}

\section{Authors}

 The CIL parser was developed starting from Hugues Casse's \t{frontc}
front-end for C although all the files from the \t{frontc} distribution have
been changed very extensively. The intermediate language and the elaboration
stage are all written from scratch. The main author is
\ahref{mailto:necula@cs.berkeley.edu}{George Necula}, with significant
contributions from \ahref{mailto:smcpeak@cs.berkeley.edu}{Scott McPeak},
\ahref{mailto:weimer@cs.berkeley.edu}{Westley Weimer}, Raymond To and Aman
Bhargava.

 This work is based upon work supported in part by the National Science
Foundation under Grants No. 9875171, 0085949 and 0081588, and gifts from
Microsoft Research. Any opinions, findings, and conclusions or recommendations
expressed in this material are those of the author(s) and do not necessarily
reflect the views of the National Science Foundation or the other sponsors.

\section{License}

Copyright (c) 2001-2002, 
\begin{itemize}
\item George C. Necula    <necula@cs.berkeley.edu>
\item Scott McPeak        <smcpeak@cs.berkeley.edu>
\item Wes Weimer          <weimer@cs.berkeley.edu>
\end{itemize}
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright notice,
this list of conditions and the following disclaimer in the documentation
and/or other materials provided with the distribution.

3. The names of the contributors may not be used to endorse or promote
products derived from this software without specific prior written
permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE.

\section{Bug reports}
 
 We are certain that there are still some remaining bugs in CIL. If you find
one please send email to \ahref{mailto:necula@cs.berkeley.edu}{George
Necula}.  

\section{Changes}\label{sec-changes}
\begin{itemize}
\item {\bf January 29, 2003}: Added the logical AND and OR operators.
Exapanded the translation to CIL to handle more complicated initializers
(including those that contain logical operators).
\item {\bf January 28, 2003}: {\bf Released version 1.0.6}
\item {\bf January 28, 2003}: Added support for the new handling of
variable-argument functions in new versions of \t{glibc}. 
\item {\bf January 19, 2003}: Added support for declarations in interpreted
  constructors. Relaxed the semantics of the patterns for variables. 
\item {\bf January 17, 2003}: Added built-in prototypes for the gcc built-in
  functions. Changed the \t{pGlobal} method in the printers to print the
  carriage return as well.
\item {\bf January 9, 2003}: Reworked lexer and parser's strategy for
  tracking source file names and line numbers to more closely match
  typical native compiler behavior.  The visible CIL interface is
  unchanged.
\item {\bf January 9, 2003}: Changed the interface to the alpha convertor. Now
you can pass a list where it will record undo information that you can use to
revert the changes that it makes to the scope tables.
\item {\bf January 6, 2003}: {\bf Released version 1.0.5}
\item {\bf January 4, 2003}: Changed the interface for the Formatcil module.
  Now the placeholders in the pattern have names. Also expanded the
  documentation of the Formatcil module.
  Now the placeholders in the pattern have names.
\item {\bf January 3, 2003}: Extended the \t{rmtmps} module to also remove
  unused labels that are generated in the conversion to CIL. This reduces the
  number of warnings that you get from \t{gcc} afterwards.
\item {\bf December 17, 2002}: Fixed a few bugs in CIL related to the
  representation of string literals. The standard says that a string literal
  is an array. In CIL, a string literal has type pointer to character. This is
  Ok, except as an argument of sizeof. To support this exception, we have
  added to CIL the expression constructor SizeOfStr. This allowed us to fix
  bugs with computing \t{sizeof("foo bar")} and \t{sizeof((char*)"foo bar")}
  (the former is 8 and the latter is 4).

\item {\bf December 8, 2002}: Fixed a few bugs in the lexer and parser
  relating to hex and octal escapes in string literals.  Also fixed
  the dependencies between the lexer and parser.
\item {\bf December 5, 2002}: Fixed visitor bugs that were causing
  some attributes not to be visited and some queued instructions to be
  dropped.
\item {\bf December 3, 2002}: Added a transformation to catch stack
  overflows.  Fixed the heapify transformation.
\item {\bf October 14, 2002}: CIL is now available under the BSD license
(see the License section or the file LICENSE).  {\bf Released version 1.0.4}
\item {\bf October 9, 2002}: More FreeBSD configuration changes, support
for the GCC-ims {\tt \_\_signed} and {\tt \_\_volatile}. Thanks to Axel
Simon for pointing out these problems. {\bf Released version 1.0.3}
\item {\bf October 8, 2002}: FreeBSD configuration and porting fixes.
Thanks to Axel Simon for pointing out these problems. 
\item {\bf September 10, 2002}: Fixed bug in conversion to CIL. Now we drop
all ``const'' qualifiers from the types of locals, even from the fields of
local structures or elements of arrays.
\item {\bf September 7, 2002}: Extended visitor interface to distinguish visitng
  offsets inside lvalues from offsets inside initializer lists.
\item {\bf September 7, 2002}: {\bf Released version 1.0.1}
\item {\bf September 6, 2002}: Extended the patcher with the \t{ateof} flag.
\item {\bf September 4, 2002}: Fixed bug in the elaboration to CIL. In some
cases constant folding of \t{||} and \t{&&} was computed wrong.
\item {\bf September 3, 2002}: Fixed the merger documentation. 
\item {\bf August 29, 2002}: {\bf Released version 1.0.0.}
\item {\bf August 29, 2002}: Started numbering versions with a major nubmer,
minor and revisions. Released version 1.0.0.
\item {\bf August 25, 2002}: Fixed the implementation of the unique
identifiers for global variables and composites. Now those identifiers are
globally unique.
\item {\bf August 24, 2002}: Added to the machine-dependent configuration the
\t{sizeof{void}}. It is 1 on gcc and 0 on MSVC. Extended the implementation of
\t{Cil.bitsSizeOf} to handle this (it was previously returning an error when
trying to compute the size of \t{void}).
\item {\bf August 24, 2002}: Changed the representation of structure and
unions to distinguish between undefined structures and those that are defined
to be empty (allowed on gcc). The sizeof operator is undefined for the former
and returns 0 for the latter.
\item {\bf August 22, 2002}: Apply a patch from Richard H. Y. to support
FreeBSD installations. Thanks, Richard!
\item {\bf August 12, 2002}: Fixed a bug in the translation of wide-character
strings. Now this translation matches that of the underlying compiler. Changed
the implementation of the compiler dependencies.
\item {\bf May 25, 2002}: Added interpreted constructors and destructors.
\item {\bf May 17, 2002}: Changed the representation of functions to move the
``inline'' information to the varinfo. This way we can print the ``inline''
even in declarations which is what gcc does. 
\item {\bf May 15, 2002}: Changed the visitor for initializers to make two
tail-recursive passes (the second is a \t{List.rev} and only done if one of
the initializers change). This prevents \t{Stack\_Overflow} for large
initializers. Also improved the processing of initializers when converting to
CIL. 
\item {\bf May 15, 2002}: Changed the front-end to allow the use of \t{MSVC}
mode even on machines that do not have MSVC. The machine-dependent parameters
for GCC will be used in that case. 
\item {\bf May 11, 2002}: Changed the representation of formals in function
types. Now the function type is purely functional. 
\item {\bf May 4, 2002}: Added the function
\cilvalref{visitCilFileSameGlobals} and changed \cilvalref{visitCilFile} to be
tail recursive. This prevents stack overflow on huge files.
\item {\bf February 28, 2002}: Changed the significance of the
\t{CompoundInit} in \ciltyperef{init} to allow for missing initializers at the
end of an array initializer. Added the API function
\cilvalref{foldLeftCompoundAll}.
\end{itemize}

\end{document}



